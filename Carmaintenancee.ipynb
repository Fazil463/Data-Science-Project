{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Vehicle Maintenance Data Analysis</h1>\n",
    "<h3 align=\"center\">October 21, 2024</h3>\n",
    "\n",
    "\n",
    "\n",
    "## 1. Vehicle Maintenance Data Analysis\n",
    "\n",
    "### 1.1 Introduction\n",
    "In the realm of fleet management, data on vehicle maintenance plays a pivotal role in ensuring operational efficiency and safety. As vehicles are subjected to various stresses over time—such as mileage, driving conditions, and weather—regular monitoring and maintenance become essential. Analyzing vehicle maintenance data helps fleet managers make informed decisions that enhance vehicle reliability, reduce downtime, and optimize maintenance costs.\n",
    "\n",
    "With an increasing reliance on data analytics, businesses can identify patterns in vehicle performance, enabling proactive maintenance strategies. This approach minimizes unexpected breakdowns, improves service schedules, and ultimately enhances customer satisfaction. Additionally, by leveraging insights from this data, companies can strategically allocate resources, forecast maintenance needs, and implement effective cost management strategies.\n",
    "\n",
    "### 1.1.1 Dataset Overview\n",
    "The vehicle maintenance dataset contains comprehensive records detailing various aspects of vehicle performance and maintenance history. Each column provides critical insights that can be utilized for effective fleet management. Here’s a detailed breakdown of the 20 columns in the dataset:\n",
    "\n",
    "- **Vehicle_Model**: This column indicates the specific model of the vehicle (e.g., Truck, Van, Bus). Analyzing maintenance patterns by model can highlight which types of vehicles are more prone to issues, helping businesses make informed purchasing decisions and tailor their maintenance practices accordingly.\n",
    "\n",
    "- **Mileage**: This represents the distance traveled by the vehicle since its last maintenance, measured in miles. Higher mileage generally correlates with increased wear and tear, indicating that vehicles may require more frequent inspections and servicing. Tracking mileage also aids in planning maintenance schedules based on usage.\n",
    "\n",
    "- **Maintenance_History**: This column describes the overall condition of the vehicle's maintenance, categorized as \"Good,\" \"Average,\" or \"Poor.\" A thorough maintenance history allows fleet managers to evaluate each vehicle’s reliability and may influence decisions on whether to retain or replace aging vehicles.\n",
    "\n",
    "- **Reported_Issues**: The number of issues reported by drivers or during inspections. Monitoring this column helps identify common problems that may affect certain models or types of vehicles, guiding preventive measures and targeted training for drivers on vehicle care.\n",
    "\n",
    "- **Vehicle_Age**: The age of the vehicle in years is a critical factor affecting maintenance needs. Older vehicles often experience more frequent breakdowns and may require more costly repairs. Understanding the age distribution of the fleet can inform long-term investment and replacement strategies.\n",
    "\n",
    "- **Fuel_Type**: This indicates the type of fuel the vehicle uses (e.g., Petrol, Diesel, Electric). Different fuel types come with varying maintenance needs and operational costs. Analyzing fuel type can assist in optimizing fuel efficiency strategies and managing related expenses.\n",
    "\n",
    "- **Transmission_Type**: Specifies whether the vehicle has a \"Manual\" or \"Automatic\" transmission. This distinction can affect maintenance frequency and costs, as well as driver training and vehicle operation practices.\n",
    "\n",
    "- **Engine_Size**: Measured in cubic centimeters (cc), engine size influences the vehicle's performance, fuel efficiency, and maintenance needs. Larger engines may experience more wear under heavy loads, leading to potential differences in maintenance practices.\n",
    "\n",
    "- **Odometer_Reading**: This reflects the total distance traveled by the vehicle since it was first used, also in miles. Keeping track of odometer readings is essential for scheduling regular maintenance and ensuring compliance with warranty conditions.\n",
    "\n",
    "- **Last_Service_Date**: The date of the most recent servicing helps managers plan future maintenance and ensure that no vehicle goes overdue for its scheduled checks. This can prevent costly repairs due to neglect.\n",
    "\n",
    "- **Warranty_Expiry_Date**: This indicates when the vehicle’s warranty expires, crucial for financial planning and cost management. Understanding warranty status can inform decisions about whether to perform maintenance in-house or outsource to authorized service centers.\n",
    "\n",
    "- **Owner_Type**: Specifies whether the vehicle is \"First,\" \"Second,\" or \"Third\" hand, which often reflects the vehicle's condition and maintenance history. Vehicles with more previous owners may have varied upkeep, impacting their reliability and potential repair costs.\n",
    "\n",
    "- **Insurance_Premium**: This represents the cost of insuring the vehicle, which can vary based on several factors, including vehicle type and reported accidents. Higher premiums can indicate a higher risk profile, prompting more careful monitoring of those vehicles.\n",
    "\n",
    "- **Service_History**: The total number of past maintenance services performed. A higher service history count may suggest a vehicle is prone to issues, leading managers to scrutinize its future role in the fleet.\n",
    "\n",
    "- **Accident_History**: The number of accidents involving the vehicle. A vehicle with a higher accident history may face increased maintenance needs and present safety risks, necessitating more frequent inspections.\n",
    "\n",
    "- **Fuel_Efficiency**: This measures the vehicle's fuel consumption rate (e.g., miles per gallon). Monitoring fuel efficiency is essential for cost management; a drop in efficiency can indicate the need for engine tuning or other maintenance actions.\n",
    "\n",
    "- **Tire_Condition**: Describes the current state of the tires (e.g., \"New,\" \"Good,\" \"Worn Out\"). Regular tire inspections are vital for safety and can help prevent accidents caused by tire failure.\n",
    "\n",
    "- **Brake_Condition**: Indicates the state of the vehicle's braking system (e.g., \"New,\" \"Good,\" \"Worn Out\"). Brake condition is critical for vehicle safety and should be routinely checked to ensure operational reliability.\n",
    "\n",
    "- **Battery_Status**: Reflects the health of the vehicle’s battery, categorized as \"New,\" \"Good,\" or \"Weak.\" Battery maintenance is crucial to prevent unexpected failures, especially in cold weather or high-demand situations.\n",
    "\n",
    "- **Need_Maintenance**: A binary indicator (0 or 1) indicating whether the vehicle currently requires maintenance. This column aids fleet managers in prioritizing which vehicles need immediate attention, facilitating timely interventions.\n",
    "\n",
    "### 1.1.2 Data Insights \n",
    "\n",
    "#### Maintenance Optimization\n",
    "- **Predictive Maintenance Strategies**: Analyzing the **Maintenance_History** and **Reported_Issues** can allow for the development of predictive maintenance models. By identifying patterns in maintenance needs based on **Vehicle_Age** and **Mileage**, fleet managers can predict when a vehicle is likely to require service, thereby reducing unplanned maintenance and enhancing operational uptime.\n",
    "\n",
    "#### Cost Analysis\n",
    "- **Total Cost of Ownership**: Combining the **Insurance_Premium**, **Maintenance_History**, and **Fuel_Efficiency** allows for a comprehensive view of the total cost of ownership for each vehicle. This analysis helps in making decisions about whether to keep or replace vehicles, as it evaluates both direct and indirect costs associated with vehicle operation.\n",
    "- **Impact of Fuel Type on Operating Costs**: Analyzing the **Fuel_Type** in relation to **Fuel_Efficiency** and **Insurance_Premium** can identify which fuel types provide the best cost-benefit ratio. This insight can inform future purchasing decisions based on fuel cost fluctuations and environmental considerations.\n",
    "\n",
    "#### Vehicle Performance Trends\n",
    "- **Fuel Efficiency Over Time**: Monitoring **Fuel_Efficiency** in correlation with **Mileage** and **Vehicle_Age** can help identify trends in performance degradation. Regular analysis may indicate when specific vehicles require tuning or adjustments to maintain optimal fuel efficiency.\n",
    "- **Comparative Analysis by Model**: Evaluating the **Vehicle_Model** against **Reported_Issues** and **Maintenance_History** can reveal which models perform best over time. This insight can help in fleet composition decisions, ensuring a balanced and reliable fleet.\n",
    "\n",
    "#### Safety and Reliability\n",
    "- **Correlating Accident History with Maintenance**: Investigating the relationship between **Accident_History** and **Maintenance_History** can provide insights into how regular maintenance influences safety outcomes. Vehicles with poor maintenance records and high accident rates may indicate a need for stricter maintenance enforcement.\n",
    "- **Predicting Failures Through Condition Indicators**: Analyzing the **Tire_Condition**, **Brake_Condition**, and **Battery_Status** alongside the **Need_Maintenance** indicator can create a holistic view of vehicle safety. This can enable fleet managers to prioritize vehicles that show multiple warning signs for immediate servicing, thereby preventing potential accidents.\n",
    "\n",
    "#### Resource Allocation\n",
    "- **Optimal Scheduling of Maintenance**: By analyzing **Last_Service_Date** in conjunction with **Odometer_Reading**, fleet managers can optimize their maintenance scheduling. This ensures that vehicles do not exceed recommended service intervals, thus reducing wear and prolonging vehicle life.\n",
    "- **Training Needs Identification**: Monitoring **Reported_Issues** alongside **Owner_Type** and **Transmission_Type** can reveal the need for targeted driver training programs. Understanding which vehicles experience more issues can help in devising training initiatives focused on driver habits that contribute to maintenance problems.\n",
    "\n",
    "#### Predictive Maintenance Models\n",
    "- **Machine Learning Applications**: Utilizing advanced analytics and machine learning algorithms can enable the development of predictive models that identify potential vehicle failures based on historical maintenance data. This proactive approach not only improves vehicle reliability but also enhances cost-effectiveness in the long term.\n",
    "- **Data-Driven Decision Making**: With a robust dataset, fleet managers can create dashboards that visualize key metrics, allowing for real-time monitoring and informed decision-making. This empowers managers to react swiftly to emerging trends and issues, maintaining operational efficiency.\n",
    "\n",
    "#### Environmental Impact\n",
    "- **Sustainability Initiatives**: By analyzing the relationship between **Fuel_Type** and **Fuel_Efficiency**, fleet managers can identify opportunities to transition towards more sustainable fuel options. This can not only reduce operational costs but also align with corporate social responsibility goals aimed at reducing the environmental footprint.\n",
    "- **Long-Term Emission Reductions**: Understanding how vehicle maintenance influences emissions can provide insights into compliance with environmental regulations. Ensuring vehicles are regularly serviced can help maintain optimal fuel efficiency and reduce harmful emissions.\n",
    "\n",
    "By employing a data-driven approach to vehicle maintenance, fleet managers can make informed decisions that optimize operational efficiency, reduce costs, and enhance overall fleet reliability. This detailed explanation provides a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Processing Summary\n",
    "\n",
    "1. **Data Loading and Initial Inspection**:\n",
    "   - Loaded the dataset and reviewed its structure, including column names, data types, and missing values.\n",
    "   - Initial exploration helped identify key variables related to vehicle maintenance, such as `Vehicle_Model`, `Mileage`, `Maintenance_History`, `Reported_Issues`, `Fuel_Type`, `Transmission_Type`, `Vehicle_Age`, `Service_History`, `Accident_History`, `Battery_Status`, and `Need_Maintenance`.\n",
    "\n",
    "2. **Data Cleaning**:\n",
    "   - Checked for and handled any missing or erroneous values to ensure accuracy in analysis.\n",
    "   - Ensured data consistency across categorical variables (e.g., `Fuel_Type`, `Transmission_Type`, `Battery_Status`), addressing any inconsistencies to allow for accurate grouping and comparison.\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "   - Created additional insights by calculating variables like average maintenance frequency and age categories for vehicles.\n",
    "   - Converted date columns (`Last_Service_Date` and `Warranty_Expiry_Date`) to datetime format to calculate time-based intervals and understand maintenance timing.\n",
    "\n",
    "4. **Exploratory Data Analysis (EDA)**:\n",
    "   - Conducted descriptive statistics and visualizations to understand distributions and relationships among variables.\n",
    "   - Key focus areas included:\n",
    "     - Relationship between `Vehicle_Age` and `Need_Maintenance`.\n",
    "     - Fuel efficiency patterns across different `Fuel_Type` and `Engine_Size`.\n",
    "     - Impact of `Service_History` and `Accident_History` on maintenance needs and insurance premiums.\n",
    "   - Examined common maintenance issues based on `Battery_Status` and `Brake_Condition`.\n",
    "\n",
    "5. **Correlation and Pattern Analysis**:\n",
    "   - Analyzed correlations between quantitative variables such as `Mileage`, `Odometer_Reading`, `Fuel_Efficiency`, and `Insurance_Premium`.\n",
    "   - Investigated the relationship between maintenance needs and key factors, including vehicle age, service history, and accident history.\n",
    "\n",
    "6. **Key Insights Extraction**:\n",
    "   - Summarized key insights from the analysis, highlighting the impact of consistent maintenance, the advantages of electric and fuel-efficient vehicles, and the need for focused attention on critical components like batteries and brakes.\n",
    "\n",
    "7. **Future Recommendations**:\n",
    "   - Based on insights, developed actionable recommendations for predictive maintenance, vehicle replacement with electric options, insurance optimization, and monitoring protocols to enhance fleet performance and sustainability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The objective of this project is to develop a machine learning model that predicts the maintenance needs of vehicles based on various characteristics. By analyzing features such as mileage, vehicle age, maintenance history, and fuel type, this model aims to assist fleet managers and individual vehicle owners in scheduling timely maintenance. The ultimate goal is to enhance vehicle performance and reduce the risk of unexpected breakdowns, thereby improving operational efficiency and safety.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "In the automotive industry, maintaining vehicle performance and preventing failures is critical for ensuring safety and reducing operational costs. Predictive maintenance offers significant cost-saving opportunities and allows for better resource allocation. This project leverages historical data related to vehicle characteristics and maintenance history to predict whether a vehicle requires maintenance (1 = Yes, 0 = No). The key focus is to develop a model that can proactively identify when a vehicle is likely to need servicing, helping to avoid costly breakdowns and improve operational efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary\n",
    "\n",
    "| Feature               | Description                                        | Data Type   | Example Values               |\n",
    "|-----------------------|----------------------------------------------------|-------------|------------------------------|\n",
    "| **Vehicle_Model**      | Type of the vehicle (e.g., Car, SUV, Truck)        | Categorical | Car, SUV, Truck              |\n",
    "| **Mileage**            | Total mileage covered by the vehicle               | Numeric     | 15,000, 35,000, 120,000       |\n",
    "| **Maintenance_History**| Quality of previous maintenance                    | Categorical | Good, Average, Poor           |\n",
    "| **Vehicle_Age**        | Age of the vehicle in years                        | Numeric     | 1, 5, 10                      |\n",
    "| **Fuel_Type**          | Type of fuel used by the vehicle                   | Categorical | Gasoline, Diesel              |\n",
    "| **Last_Service_Date**  | Date of the last service performed                 | Date        | 2023-06-15                    |\n",
    "| **Engine_Health**      | Status of engine health                            | Categorical | Good, Fair, Poor              |\n",
    "| **Tire_Condition**     | Condition of the tires                            | Categorical | New, Worn                     |\n",
    "| **Weather_Conditions** | Conditions during the last trip                    | Categorical | Sunny, Rainy, Snowy           |\n",
    "| **Driving_Style**      | Style of driving                                  | Categorical | Aggressive, Moderate          |\n",
    "| **Last_Fuel_Consumption** | Fuel consumption during the last trip            | Numeric     | 25, 18.5, 22                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'D:\\Downloads\\archive (6)maintenance\\vehicle_maintenance_data.csv')\n",
    "maintenance=pd.DataFrame(df)\n",
    "maintenance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# checking null values\n",
    "maintenance.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheching for null values in each column\n",
    "maintenance.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying unique values in each row\n",
    "maintenance.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for any duplicate rows\n",
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance['Last_Service_Date']=pd.to_datetime(maintenance['Last_Service_Date'],utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime type\n",
    "maintenance['Last_Service_Date'] = pd.to_datetime(maintenance['Last_Service_Date'], errors='coerce')\n",
    "maintenance['Warranty_Expiry_Date'] = pd.to_datetime(maintenance['Warranty_Expiry_Date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers in numerical columns using interquartile range (IQR) for key columns\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = df[(df[column] < (Q1 - 1.5 * IQR)) | (df[column] > (Q3 + 1.5 * IQR))]\n",
    "    return len(outliers), outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers in 'Mileage', 'Odometer_Reading', and 'Insurance_Premium'\n",
    "mileage_outliers = detect_outliers_iqr(maintenance, 'Mileage')\n",
    "odometer_outliers = detect_outliers_iqr(maintenance, 'Odometer_Reading')\n",
    "insurance_premium_outliers = detect_outliers_iqr(maintenance, 'Insurance_Premium')\n",
    "\n",
    "\n",
    "print(f\"\\nNumber of outliers in 'Mileage': {mileage_outliers[0]}\")\n",
    "print(f\"Number of outliers in 'Odometer_Reading': {odometer_outliers[0]}\")\n",
    "print(f\"Number of outliers in 'Insurance_Premium': {insurance_premium_outliers[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize categorical data by converting all text columns to lowercase for consistency\n",
    "text_columns = maintenance.select_dtypes(include=['object']).columns\n",
    "maintenance[text_columns] = maintenance[text_columns].apply(lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance_backup=maintenance.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance.to_csv('cleaned_car_maintenance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate numerical variables\n",
    "numeric_df =maintenance.select_dtypes(include=np.number)\n",
    "\n",
    "# Isolate categorical variables\n",
    "categorical_df = maintenance.select_dtypes(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 What is the average mileage of vehicles that require maintenance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for vehicles that require maintenance\n",
    "maintenance_need = df[df['Need_Maintenance'] == 1]\n",
    "\n",
    "# Calculate the average mileage for vehicles that require maintenance\n",
    "average_mileage = maintenance_need['Mileage'].mean()\n",
    "\n",
    "print(f\"The average mileage of vehicles that require maintenance is {average_mileage:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The average mileage of vehicles that require maintenance, based on the dataset, is 54,936.15 miles. This figure is crucial for several reasons, as it highlights key insights into vehicle performance and maintenance needs:\n",
    "\n",
    "1. **Wear and Tear Over Time**  \n",
    "   Mileage is a direct indicator of how much a vehicle has been used. The more miles a vehicle accumulates, the more wear and tear it experiences on critical components such as the engine, transmission, tires, and brakes. An average mileage of around 55,000 miles suggests that vehicles typically reach a point where mechanical parts may start to wear out and require replacement or servicing.\n",
    "\n",
    "   **Explanation:** After several years of usage, especially around the 50,000–60,000 mile range, it is common for parts like brake pads, tires, suspension, or even engine components to show signs of wear. This results in a greater likelihood of needing maintenance.\n",
    "\n",
    "2. **Routine Maintenance Milestones**  \n",
    "   Vehicle manufacturers often set specific mileage-based service intervals. Common intervals for major services are 30,000, 60,000, and 90,000 miles. Since the average is close to one of these key service intervals, it suggests that vehicles approaching or crossing the 50,000-mile threshold are due for maintenance as part of routine checks recommended by manufacturers.\n",
    "\n",
    "   **Explanation:** At 50,000+ miles, many vehicles require significant scheduled maintenance such as fluid replacements (engine oil, brake fluid, coolant), checking the timing belt, and inspection of major systems (suspension, transmission). Not adhering to these service schedules can increase the likelihood of issues that demand repairs.\n",
    "\n",
    "3. **Vehicle Age and Condition**  \n",
    "   Mileage can be a rough proxy for a vehicle’s age. Older vehicles with higher mileage are more prone to developing problems due to both the usage and aging of components. This average mileage figure may correspond to vehicles that are several years old, and this aging increases the probability of maintenance being required.\n",
    "\n",
    "   **Explanation:** As vehicles accumulate miles, components begin to degrade due to age, heat, stress, and other environmental factors. Parts like batteries, belts, hoses, and seals naturally wear out over time, and older vehicles are more likely to experience these issues.\n",
    "\n",
    "4. **Impact on Maintenance Costs**  \n",
    "   Vehicles that have reached this mileage threshold often incur higher maintenance costs compared to those with lower mileage. Owners of vehicles with mileage near or above 55,000 may start facing not just regular maintenance, but also unscheduled repairs due to unexpected failures in systems such as brakes, fuel systems, and even electrical components.\n",
    "\n",
    "   **Explanation:** Once a vehicle crosses this threshold, repair frequency tends to increase, requiring preventive maintenance or replacement of components like spark plugs, alternators, or water pumps. This is typical for both individual owners and fleet vehicles.\n",
    "\n",
    "5. **Diverse Vehicle Models and Driving Conditions**  \n",
    "   The dataset likely includes various vehicle models (cars, trucks, motorcycles, etc.), and driving conditions (city, highway, off-road) affect how quickly vehicles need maintenance. For instance, vehicles used in rougher environments or subject to heavy loads may require maintenance sooner than vehicles driven under more moderate conditions.\n",
    "\n",
    "   **Explanation:** Trucks and buses, which may be subject to higher loads or harsher driving conditions, can experience wear faster than sedans or SUVs, even at the same mileage. High-mileage vehicles used in more strenuous environments are likely to face maintenance challenges earlier.\n",
    "\n",
    "6. **Possible Reasons Behind Maintenance Requirement**  \n",
    "   There are several common reasons why vehicles with an average of 54,936 miles may require maintenance:\n",
    "   - **Engine Wear:** Components such as pistons, valves, and seals experience wear as mileage increases, which may lead to performance issues, oil leaks, or reduced fuel efficiency.\n",
    "   - **Suspension System:** At this mileage, vehicles may start showing signs of suspension wear, particularly shocks and struts, which affect ride quality and safety.\n",
    "   - **Transmission Issues:** Higher mileage vehicles are more prone to transmission problems, including slipping gears or delayed shifts, which might require repairs or a full replacement.\n",
    "   - **Brake and Tire Wear:** Brake pads and tires typically wear out as mileage increases, and around 55,000 miles is a common point for replacement, depending on driving habits.\n",
    "   - **Electrical System:** Electrical issues, including problems with the alternator or battery, often arise in vehicles around this mileage due to extended use.\n",
    "\n",
    "### Conclusion Summary  \n",
    "The average mileage of **54,936.15 miles** for vehicles requiring maintenance is significant because it aligns with typical intervals for major vehicle servicing and component wear. Vehicles at or near this mileage often encounter routine maintenance issues as well as potential component failures due to normal wear and tear over time. This insight can help vehicle owners and fleet managers prepare for higher maintenance costs and take proactive measures to ensure vehicles remain operational and efficient.\n",
    "\n",
    "By understanding these mileage-based trends, businesses and individuals can better plan for repairs and maintenance, ultimately improving vehicle longevity and reducing the likelihood of unexpected breakdowns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Is there a relationship between Vehicle_Age and Fuel_Efficiency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between Vehicle_Age and Fuel_Efficiency\n",
    "correlation = maintenance['Vehicle_Age'].corr(maintenance['Fuel_Efficiency'])\n",
    "print(f'Correlation between Vehicle_Age and Fuel_Efficiency: {correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Adjusted scatter plot with jitter and transparency\n",
    "sns.scatterplot(data=maintenance, x='Vehicle_Age', y='Fuel_Efficiency', alpha=0.6)\n",
    "plt.title('Scatter Plot of Vehicle Age vs Fuel Efficiency with Jitter')\n",
    "plt.xlabel('Vehicle Age (years)')\n",
    "plt.ylabel('Fuel Efficiency (mpg)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Relationship Between Vehicle Age and Fuel Efficiency\n",
    "\n",
    "The analysis of the relationship between **Vehicle Age** and **Fuel Efficiency** resulted in a correlation coefficient of **-0.0046**, which is very close to zero. This indicates an almost non-existent linear relationship between the two variables. Essentially, as the **Vehicle Age** increases, there is no discernible pattern of increase or decrease in **Fuel Efficiency**. A correlation near zero suggests that **Fuel Efficiency** is not impacted by the age of the vehicle in a meaningful way, based on the dataset provided.\n",
    "\n",
    "### Analysis of the Graph\n",
    "Looking at the scatter plot, we can see that the data points for **Fuel Efficiency** (measured in miles per gallon) are consistently spread across all ages of vehicles. Whether the vehicle is 1 year old or 10 years old, the range of **Fuel Efficiency** remains approximately between **10 mpg** and **20 mpg**. There are no noticeable clusters or trends where older vehicles have significantly lower or higher fuel efficiency compared to newer ones. This even distribution suggests that vehicle age is not a primary factor affecting fuel efficiency, and other variables may have more influence.\n",
    "\n",
    "### Broader Implications\n",
    "Given the negligible correlation and the uniform pattern in the scatter plot, it's likely that other factors such as vehicle **Model**, **Engine Size**, **Maintenance History**, or **Driving Conditions** play a more significant role in determining fuel efficiency. For example, certain **Vehicle Types** may inherently have better fuel efficiency, regardless of age, while others may be affected by factors like engine wear, tire condition, or driving habits. Therefore, it would be beneficial to explore these additional factors to understand their impact on fuel efficiency. Vehicle owners should not overly worry about fuel performance strictly based on vehicle age, but should instead consider other aspects like **Routine Maintenance** and **Driving Behavior** to optimize fuel usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 How does Transmission_Type affect Fuel_Efficiency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate average Fuel Efficiency by Transmission Type\n",
    "average_fuel_efficiency = maintenance.groupby('Transmission_Type')['Fuel_Efficiency'].mean().reset_index()\n",
    "\n",
    "# Print the average fuel efficiency\n",
    "print(average_fuel_efficiency)\n",
    "\n",
    "# Plotting the average Fuel Efficiency based on Transmission Type\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=average_fuel_efficiency, x='Transmission_Type', y='Fuel_Efficiency', hue='Transmission_Type',palette='viridis')\n",
    "plt.title('Average Fuel Efficiency by Transmission Type')\n",
    "plt.xlabel('Transmission Type')\n",
    "plt.ylabel('Average Fuel Efficiency (mpg)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The relationship between transmission type and fuel efficiency is a critical aspect of vehicle performance that has garnered significant attention in the automotive industry. In the provided data, two transmission types—automatic and manual—exhibit closely comparable fuel efficiency figures, with automatic vehicles averaging approximately 14.99 miles per gallon (mpg) and manual vehicles slightly higher at around 14.99 mpg as well. This minimal difference suggests that the choice of transmission may not substantially impact fuel consumption for vehicles within this specific dataset.\n",
    "\n",
    "Automatic transmissions have long been considered less fuel-efficient than their manual counterparts due to the inherent design and functionality. Automatics typically use a torque converter that can lead to energy loss, while manual transmissions allow drivers more control over gear selection, potentially optimizing engine performance. However, advancements in automatic transmission technology, such as dual-clutch systems and continuously variable transmissions (CVTs), have improved fuel efficiency in automatic vehicles, narrowing the gap with manual systems. This indicates that the evolution of transmission technology could play a crucial role in fuel economy.\n",
    "\n",
    "Another critical factor to consider is the driving behavior associated with each transmission type. Manual transmissions often require more skill and engagement from the driver, who can optimize shifts for better fuel efficiency. In contrast, automatic transmissions tend to adapt to the driver's style and conditions, potentially resulting in suboptimal fuel use if the transmission does not shift effectively for specific driving scenarios. Therefore, driver experience and behavior, along with transmission design, significantly influence fuel efficiency, suggesting that further investigation into driving patterns could provide valuable insights.\n",
    "\n",
    "In summary, while the data indicates that both automatic and manual transmissions yield similar fuel efficiency, understanding the broader context is essential for making informed decisions about vehicle selection and fleet management. As manufacturers continue to innovate and enhance transmission systems, fleet operators must consider various factors—such as driving conditions, vehicle models, and maintenance practices—when evaluating fuel efficiency. Ultimately, a comprehensive approach that combines technological advancements with driver education can lead to optimized fuel consumption and overall operational efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 What is the trend in Service_History based on Vehicle_Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of service records per Vehicle_Model\n",
    "service_history_trend = maintenance.groupby('Vehicle_Model')['Service_History'].count().reset_index()\n",
    "service_history_trend.rename(columns={'Service_History': 'Total_Services'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_history_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(y='Vehicle_Model', x='Total_Services', data=service_history_trend,hue='Total_Services', palette='viridis',legend=False)\n",
    "plt.title('Trend in Service History Based on Vehicle Model')\n",
    "plt.xlabel('Vehicle Model')\n",
    "plt.ylabel('Total Services')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on the analysis of the total services rendered for different vehicle models, it is evident that the bus category leads with the highest total service count of 8,414. This substantial figure suggests that buses may undergo more frequent maintenance or servicing due to their extensive use in public transportation and commercial applications. Additionally, the sheer volume of services for buses could reflect their complexity, requiring specialized attention to ensure safety and operational efficiency.\n",
    "\n",
    "In comparison, the motorcycle category follows closely behind with a total of 8,295 services. This high service count indicates a robust demand for motorcycle maintenance, possibly driven by a growing trend of motorcycle use for both commuting and leisure activities. The slight difference in service count compared to buses might suggest that motorcycles are also prone to regular servicing, although the nature of their maintenance may differ significantly due to their mechanical and structural differences.\n",
    "\n",
    "The other vehicle models, such as suv, truck, and van, also show significant total services, ranging between 8,360 to 8,328. This proximity in numbers highlights that these vehicle types are also essential in the transport sector, suggesting that they require regular maintenance to keep them operational. The services rendered reflect the vehicle models’ popularity and the critical nature of their roles in transportation and logistics, indicating that owners of these vehicles prioritize maintenance to prolong their lifespan and ensure reliability.\n",
    "\n",
    "Overall, the data illustrates a healthy trend in service engagement across various vehicle models, with buses leading the way. This information can be valuable for stakeholders in the automotive industry, including service providers and manufacturers, to understand customer needs better and optimize service offerings. The insights gathered from this analysis could also inform marketing strategies, inventory management for spare parts, and the development of service packages tailored to the specific maintenance needs of different vehicle types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Which Fuel_Type has the highest average Odometer_Reading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "average_odometer = maintenance.groupby('Fuel_Type')['Odometer_Reading'].mean().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "average_odometer.rename(columns={'Odometer_Reading': 'Average_Odometer_Reading'}, inplace=True)\n",
    "\n",
    "# Identify the Fuel_Type with the highest average Odometer_Reading\n",
    "highest_avg_fuel_type = average_odometer.loc[average_odometer['Average_Odometer_Reading'].idxmax()]\n",
    "\n",
    "print(highest_avg_fuel_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y='Fuel_Type', x='Average_Odometer_Reading', data=average_odometer, hue='Fuel_Type',palette='viridis',legend=False\n",
    "            )\n",
    "plt.title('Average Odometer Reading by Fuel Type')\n",
    "plt.xlabel('Average Odometer Reading')\n",
    "plt.ylabel('Fuel Type')\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The analysis of average odometer readings by fuel type reveals notable insights into the usage patterns of different vehicle categories. The dataset shows that vehicles powered by petrol have the highest average odometer reading at approximately 75,661.55 kilometers, indicating that petrol vehicles are likely driven more frequently or for longer distances compared to their diesel and electric counterparts. This could reflect consumer preferences and trends in the automotive market, where petrol vehicles remain popular for their performance and availability, possibly contributing to a more extensive usage profile.\n",
    "\n",
    "Following closely behind are diesel vehicles, with an average odometer reading of around 75,657.07 kilometers. This marginally lower figure suggests that while diesel vehicles are also utilized significantly, they may be less common in the current market compared to petrol vehicles. Diesel engines are often favored for their fuel efficiency and torque, especially in commercial applications like trucks and vans. However, the slight difference in average readings could imply a shift in consumer behavior, potentially influenced by environmental considerations and the growing interest in more sustainable fuel options.\n",
    "\n",
    "Electric vehicles report an average odometer reading of approximately 75,333.30 kilometers, placing them last among the three fuel types. This lower average could indicate that electric vehicles are still in the early adoption phase, where consumers may not drive them as extensively as petrol or diesel vehicles. Factors contributing to this trend could include concerns about charging infrastructure, range anxiety, and the relatively higher initial cost of electric vehicles. However, the data also suggests that electric vehicles are being utilized effectively, as their average reading remains competitive with traditional fuel types, hinting at a positive trajectory for electric vehicle adoption in the future.\n",
    "\n",
    "Overall, the comparative analysis of average odometer readings by fuel type sheds light on the current landscape of vehicle usage. The dominance of petrol vehicles, followed closely by diesel, indicates entrenched consumer habits, while the emerging presence of electric vehicles shows potential for growth as infrastructure and technology continue to advance. As environmental awareness rises and electric vehicle technology improves, it is plausible that we will see a shift in these averages over time, reflecting changes in consumer preferences and broader societal trends towards sustainability and reduced carbon footprints. Stakeholders in the automotive industry can leverage these insights to tailor their strategies, ensuring they align with evolving consumer demands and market dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Does Engine_Size correlate with Reported_Issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation\n",
    "correlation = maintenance['Engine_Size'].corr(maintenance['Reported_Issues'])\n",
    "\n",
    "print(f'Correlation between Engine Size and Reported Issues: {correlation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Engine_Size', y='Reported_Issues', data=maintenance)\n",
    "plt.title('Scatter Plot of Engine Size vs. Reported Issues')\n",
    "plt.xlabel('Engine Size')\n",
    "plt.ylabel('Reported Issues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on the Correlation Between Engine Size and Reported Issues\n",
    "\n",
    "The correlation coefficient between `Engine_Size` and `Reported_Issues` is approximately **-0.00035**, which indicates an extremely weak negative correlation. This suggests that there is virtually no linear relationship between engine size and the number of reported issues in the dataset. A correlation value close to zero implies that changes in engine size do not significantly impact the frequency or severity of reported problems. This finding is crucial for understanding how engine specifications relate to vehicle reliability.\n",
    "\n",
    "Given the negligible correlation, it can be inferred that other factors likely play a more significant role in determining reported issues than engine size alone. Variables such as vehicle make and model, maintenance practices, driving conditions, and usage patterns may have a more pronounced effect on the frequency of reported issues. This lack of a strong correlation suggests that while engine size may contribute to vehicle performance characteristics, it does not inherently correlate with mechanical failures or complaints.\n",
    "\n",
    "Moreover, the weak negative correlation could imply that, in some cases, larger engines might be associated with fewer reported issues, but this relationship is too weak to be considered statistically significant. This observation could point to the potential advantages of larger engines in specific contexts, such as robustness and durability. However, without more rigorous analysis and larger datasets, it is challenging to draw definitive conclusions regarding the reliability of vehicles with varying engine sizes.\n",
    "\n",
    "In summary, while the analysis reveals an almost negligible correlation between engine size and reported issues, it highlights the complexity of factors influencing vehicle reliability. Further research is warranted to explore the impact of other variables on reported issues, potentially leading to a more comprehensive understanding of vehicle performance and reliability. Stakeholders in the automotive industry, including manufacturers and consumers, can benefit from recognizing that engine size is only one of many elements influencing vehicle durability and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 What is the distribution of Accident_History across different Vehicle_Models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_history=maintenance.groupby('Vehicle_Model')['Accident_History'].count().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of Accident History across different Vehicle Models\n",
    "plt.figure(figsize=(12, 8))\n",
    "accident_history.plot(kind='bar', x='Vehicle_Model', color=['#66c2a5', '#fc8d62'],legend=False)\n",
    "plt.title('Distribution of Accident History Across Different Vehicle Models')\n",
    "plt.xlabel('Vehicle Model')\n",
    "plt.ylabel('Count of Accident History')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of accident history across various vehicle models reveals interesting insights into how different types of vehicles relate to reported accident histories. The table lists several vehicle models, such as buses, cars, motorcycles, SUVs, trucks, and vans, alongside their respective accident history counts. These figures indicate the total number of reported incidents for each vehicle type, providing a quantitative basis for analyzing patterns in accident occurrences.\n",
    "\n",
    "The bus has the highest recorded accident history at 8,414 incidents, followed closely by vans at 8,400. This suggests that larger vehicles, which typically accommodate more passengers and freight, may be more prone to accidents, possibly due to their size and the complexities involved in their operation. This trend could be influenced by factors such as the environments in which these vehicles operate, which may include urban settings with heavier traffic, thereby increasing the likelihood of accidents.\n",
    "\n",
    "Conversely, the car, with 8,203 incidents, and the motorcycle, with 8,295, also display significant accident histories, albeit lower than buses and vans. This finding highlights the fact that smaller vehicles are not exempt from accidents. The relatively high number of reported incidents for motorcycles may be attributed to their vulnerability on the road compared to larger vehicles. Motorcycles often have a higher risk factor due to the lack of protective structures around the rider, making them more susceptible to serious accidents.\n",
    "\n",
    "On the other hand, the SUV and truck categories, with 8,360 and 8,328 reported incidents respectively, show that these larger vehicles, while generally perceived as safer due to their mass, still contribute significantly to accident statistics. Overall, the data underscores the need for targeted safety measures and driver education tailored to specific vehicle types. Understanding the unique challenges and risks associated with each vehicle model can aid in developing strategies to reduce accidents and improve road safety across all vehicle categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Which Owner_Type has the highest Need_Maintenance percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Owner_Type and calculate the percentage of Need_Maintenance\n",
    "maintenance_counts = maintenance.groupby('Owner_Type')['Need_Maintenance'].agg(['sum', 'count'])\n",
    "maintenance_counts['Need_Maintenance_Percentage'] = (maintenance_counts['sum'] / maintenance_counts['count']) * 100\n",
    "\n",
    "# Find the Owner_Type with the highest Need_Maintenance percentage\n",
    "highest_maintenance = maintenance_counts['Need_Maintenance_Percentage'].idxmax()\n",
    "highest_percentage = maintenance_counts['Need_Maintenance_Percentage'].max()\n",
    "\n",
    "# Output the result\n",
    "print(f\"The Owner_Type with the highest Need_Maintenance percentage is '{highest_maintenance}' with a percentage of {highest_percentage:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y=maintenance_counts.index, x=maintenance_counts['Need_Maintenance_Percentage'], hue=maintenance_counts.index,palette='viridis')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Need Maintenance Percentage by Owner Type', fontsize=16)\n",
    "plt.xlabel('Owner Type', fontsize=12)\n",
    "plt.ylabel('Need Maintenance Percentage (%)', fontsize=12)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The bar chart illustrates the distribution of vehicles requiring maintenance across different owner types. The three categories—'first,' 'second,' and 'third'—represent different groups of vehicle owners, and the graph highlights the percentage of vehicles in each group that require maintenance. The chart visually shows that each category has a relatively high percentage of vehicles that need maintenance, with values close to or exceeding 80%.\n",
    "\n",
    "The 'first' owner type exhibits the highest percentage of vehicles needing maintenance, with a rate above 80%. This could indicate that vehicles owned by this category are either older, subjected to heavier usage, or perhaps maintained less frequently. The high percentage suggests a pressing need for attention within this owner type, implying that either their vehicles are more susceptible to wear and tear, or maintenance practices are insufficient.\n",
    "\n",
    "The 'second' owner type, while still showing a substantial need for maintenance, has a slightly lower percentage than the 'first' group. The relatively high maintenance rate may be due to similar factors affecting the first group—age of the vehicles or intensity of use—but could also reflect slightly better maintenance practices or different vehicle types that are less prone to requiring frequent upkeep.\n",
    "\n",
    "The 'third' owner type, while exhibiting the lowest percentage of vehicles needing maintenance, still has a significant maintenance requirement. This suggests that even within this group, maintenance is a key issue, though the lower rate could imply better care practices, newer vehicles, or simply less intensive use. In any case, all three owner types have a high need for vehicle maintenance, which suggests that maintenance practices across the board could be improved.\n",
    "\n",
    "Overall, the data implies that regardless of ownership type, vehicles in the dataset tend to require regular attention to avoid mechanical issues. The differences in percentages might point to variations in how these vehicles are used or maintained, but the overarching conclusion is that a focus on improving vehicle maintenance protocols would benefit all categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.12 How does Mileage affect the likelihood of Need_Maintenance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins = [0, 20000, 40000, 60000, 80000, 100000, 120000, 140000, 160000, 180000, 200000]\n",
    "labels = ['0-20k', '20k-40k', '40k-60k', '60k-80k', '80k-100k', '100k-120k', '120k-140k', '140k-160k', '160k-180k', '180k-200k']\n",
    "maintenance_counts['Mileage_Range']=pd.cut(maintenance['Mileage'],bins=bins,labels=labels)                                           \n",
    "\n",
    "# Group by the Mileage Range and calculate the percentage of Need_Maintenance\n",
    "mileage_maintenance = maintenance.groupby('Mileage_Range')['Need_Maintenance'].agg(['sum','count'])\n",
    "mileage_maintenance['Maintenance_Percentage'] = (mileage_maintenance['sum'] / mileage_maintenance['count']) * 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mileage_maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(mileage_maintenance.index, mileage_maintenance['Maintenance_Percentage'], color='lightblue')\n",
    "plt.title('Maintenance Likelihood Based on Mileage')\n",
    "plt.xlabel('Mileage Range')\n",
    "plt.ylabel('Need Maintenance (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The distribution of Need_Maintenance based on mileage reveals notable trends, particularly in the 20k-60k mileage range. For vehicles with mileage between 20k-40k, the Need_Maintenance percentage is approximately 80.7%, indicating that a significant portion of vehicles in this range require maintenance. The data suggests that vehicles begin to accumulate wear and tear early in their lifespan, as seen from the high percentage of maintenance needed within this relatively low mileage range. This could reflect regular maintenance requirements as vehicles transition out of their initial \"new\" phase.\n",
    "\n",
    "Similarly, the mileage range of 40k-60k shows an even slightly higher Need_Maintenance percentage at 81.2%. This increase, though slight, confirms that as vehicles age and are driven longer distances, the likelihood of requiring maintenance continues to rise. Vehicles in this range are likely seeing increased maintenance needs due to components experiencing wear from sustained usage, such as engine, brakes, and tires. The continued high maintenance percentage suggests that proactive maintenance is crucial in preventing significant wear-related issues.\n",
    "\n",
    "Interestingly, the 60k-80k mileage range exhibits a slightly lower percentage of 80.9%, but it remains consistent with the high maintenance needs of earlier mileage ranges. This indicates that after surpassing 60k miles, vehicles still require substantial maintenance attention. Many vehicle warranties tend to expire after this mileage, possibly increasing the owners' responsibility for identifying and addressing maintenance concerns. Nonetheless, vehicles that have been well-maintained earlier may face slightly fewer needs at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.13 What is the impact of Last_Service_Date on Fuel_Efficiency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime  import datetime\n",
    "# Convert Last_Service_Date to datetime, and ensure it's tz-naive\n",
    "maintenance['Last_Service_Date'] = pd.to_datetime(maintenance['Last_Service_Date']).dt.tz_localize(None)\n",
    "\n",
    "# Calculate days since last service\n",
    "maintenance['Days_Since_Last_Service'] = (datetime.now() - maintenance['Last_Service_Date']).dt.days\n",
    "\n",
    "# Plotting the relationship\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(maintenance['Days_Since_Last_Service'], maintenance['Fuel_Efficiency'], alpha=0.5)\n",
    "plt.title('Impact of Days Since Last Service on Fuel Efficiency')\n",
    "plt.xlabel('Days Since Last Service')\n",
    "plt.ylabel('Fuel Efficiency')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = maintenance[['Days_Since_Last_Service', 'Fuel_Efficiency']].corr().iloc[0, 1]\n",
    "print(f'Correlation between Days Since Last Service and Fuel Efficiency: {correlation:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The scatter plot examines the relationship between the number of days since a vehicle's last service and its fuel efficiency. From the graph, it is evident that there is no clear linear or discernible pattern between these two variables. The points appear randomly distributed across the plot, suggesting that fuel efficiency remains relatively consistent over time, regardless of when the last service was performed. This lack of a trend indicates that the time elapsed since a service does not significantly impact fuel efficiency within this dataset.\n",
    "\n",
    "Moreover, while regular maintenance is essential for a vehicle's overall performance and longevity, the plot suggests that fuel efficiency is not directly tied to the frequency of service. The scatter plot does not reveal any strong positive or negative correlations, which would typically be expected if \"Days Since Last Service\" had a measurable effect on fuel efficiency. Instead, it implies that other factors, such as vehicle usage, driving conditions, or engine type, might play a more substantial role in determining fuel efficiency.\n",
    "\n",
    "In conclusion, the graph highlights that fuel efficiency in this dataset does not noticeably decline or improve as more time passes after a vehicle's last service. This insight could suggest that while maintenance is crucial for a vehicle’s health, other elements beyond service intervals should be explored when looking for factors influencing fuel efficiency. It may also be beneficial to examine additional data variables to gain a more comprehensive understanding of what affects fuel performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14 Which Vehicle_Models are most frequently reported for Maintenance_History issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Vehicle_Model and count the number of Maintenance_History issues reported\n",
    "maintenance_history_counts = maintenance.groupby('Vehicle_Model')['Maintenance_History'].count().sort_values(ascending=False)\n",
    "\n",
    "# Output the Vehicle_Models with the most reported Maintenance_History issues\n",
    "maintenance_history_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.set_theme(style=\"whitegrid\")  # Set a theme for the plot\n",
    "colors = sns.color_palette(\"pastel\")  # Custom color palette\n",
    "\n",
    "# Plotting the bar chart\n",
    "maintenance_history_counts.plot(kind='bar', color=colors)\n",
    "plt.title('Most Frequently Reported Vehicle Models for Maintenance History Issues', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Vehicle Model', fontsize=14)\n",
    "plt.ylabel('Number of Maintenance History Issues', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add horizontal gridlines\n",
    "\n",
    "# Adding data labels on top of the bars\n",
    "for index, value in enumerate(maintenance_history_counts):\n",
    "    plt.text(index, value, str(value), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided data indicates the maintenance history of various vehicle models, represented by the frequency of maintenance records associated with each model. The analysis reveals that buses have the highest number of maintenance entries at 8,414, suggesting that this vehicle type may require more frequent servicing compared to others. This could be due to the bus's larger size, heavier load capacity, and extensive usage in public transportation, which often leads to wear and tear.\n",
    "\n",
    "Following buses, vans and SUVs also demonstrate considerable maintenance needs, with 8,400 and 8,360 entries, respectively. The high maintenance figures for vans can be attributed to their versatility in both passenger and cargo transport, leading to varied usage scenarios that necessitate regular upkeep. Similarly, SUVs, known for their rugged use in diverse terrains and conditions, might face similar challenges, resulting in more frequent maintenance interventions.\n",
    "\n",
    "Conversely, trucks, motorcycles, and cars show relatively lower maintenance records, with counts of 8,328, 8,295, and 8,203, respectively. The lower figures for trucks might reflect their specialized use in freight transport, where maintenance schedules are often aligned with specific operational requirements rather than daily use. Motorcycles typically have fewer maintenance needs due to their simpler mechanical systems and lighter weight, which could account for their lower record numbers as well. Cars, while popular, might also have streamlined maintenance schedules compared to larger vehicles.\n",
    "\n",
    "In conclusion, the data illustrates a clear trend in vehicle maintenance history, where larger vehicles like buses, vans, and SUVs require more frequent servicing compared to smaller vehicles like motorcycles and cars. This insight can inform fleet management strategies, guiding the allocation of resources towards more intensive maintenance for high-usage vehicle types, ultimately enhancing operational efficiency and vehicle longevity. By focusing on the specific maintenance needs of different vehicle models, organizations can optimize their maintenance schedules and budgets effectively.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15 How does Insurance_Premium vary based on Vehicle_Age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Vehicle_Age and calculate the mean of Insurance_Premium\n",
    "insurance_premium_age = maintenance.groupby('Vehicle_Age')['Insurance_Premium'].mean()\n",
    "\n",
    "insurance_premium_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the variation of Insurance Premium based on Vehicle Age\n",
    "plt.figure(figsize=(10, 6))\n",
    "insurance_premium_age.plot(kind='line', marker='o', color='teal')\n",
    "plt.title('Variation of Insurance Premium by Vehicle Age')\n",
    "plt.xlabel('Vehicle Age (Years)')\n",
    "plt.ylabel('Average Insurance Premium')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line plot showing the variation of insurance premiums based on vehicle age reveals an interesting pattern. Initially, the Insurance Premium is relatively high for vehicles that are around 1 year old, peaking at an average premium of around 17,700. This may reflect higher premiums for newer vehicles, which are often insured at a higher value due to their current market value, and may also suggest a higher risk perception for newer, more expensive vehicles.\n",
    "\n",
    "As vehicles age from 1 to 4 years, there is a clear decline in the average insurance premium. By the 4th year, the premium dips to its lowest point, hovering around 17,300. This could indicate that vehicles in this age range are considered less valuable, and their insurance costs decline accordingly. Additionally, it may suggest that after a few years of use, vehicles have a proven track record, resulting in insurers viewing them as less risky.\n",
    "\n",
    "However, starting from 5 years onward, the premium begins to rise again, peaking sharply for vehicles around 8 years old. This spike could be due to the increased likelihood of mechanical issues or maintenance costs for older vehicles, prompting insurers to adjust premiums accordingly. Older vehicles may also require higher coverage for potential repairs or replacement of parts that are more likely to fail.\n",
    "\n",
    "Lastly, after the 8-year mark, the insurance premium slightly decreases but remains higher than for newer vehicles. This suggests that vehicles around 10 years old are considered more risky or expensive to maintain and repair, but not as risky as vehicles approaching their mid-life around 8 years. Overall, the data reflects a complex relationship between a vehicle's age and its associated insurance costs, where both newer and older vehicles can experience higher premiums for different reasons.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.16 What is the average Service_History for vehicles with Battery_Status as 'weak'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for 'weak' Battery_Status\n",
    "poor_battery = maintenance[maintenance['Battery_Status'] == 'weak']\n",
    "\n",
    "# Calculate the average of the 'Service_History' column for the filtered DataFrame\n",
    "average_service_history = poor_battery['Service_History'].mean()\n",
    "\n",
    "# Display the result in a professional format\n",
    "if average_service_history is not None:\n",
    "    print(f\"The average Service History for vehicles with 'weak' Battery Status is: {average_service_history:.2f}\")\n",
    "else:\n",
    "    print(\"No records found for vehicles with 'weak' Battery Status or 'Service_History' data is missing.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Service History for Vehicles with 'Weak' Battery Status\n",
    "\n",
    "The average service history for vehicles with a 'weak' battery status is 5.54. This figure indicates that on average, vehicles with weak batteries have undergone approximately 5 to 6 maintenance or service visits. A weak battery can be an indicator of declining performance or potential issues in the vehicle’s electrical system, leading to more frequent service visits.\n",
    "\n",
    "### Implications of Weak Battery Status\n",
    "\n",
    "A battery in a weak condition typically signals that the vehicle may experience starting problems, poor performance of electrical components, or even sudden breakdowns. This may require more regular check-ups, especially for vehicles that are heavily dependent on battery power for advanced features like electronic systems and sensors. The higher frequency of service visits, as indicated by the average service history, suggests that weak battery issues are often recurrent and demand attention from vehicle owners to avoid disruptions.\n",
    "\n",
    "### Impact on Maintenance Costs\n",
    "\n",
    "The average of 5.54 service visits also implies potential additional costs for vehicle owners. Maintenance services involving the battery often go beyond simple replacements, encompassing diagnostics and repairs of related systems like alternators, wiring, and starters. Regular servicing due to a weak battery status could lead to cumulative costs that are higher than standard maintenance. Addressing the battery's weakness early could reduce these expenses by preventing other related issues.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "In conclusion, vehicles with a weak battery status appear to require a higher-than-normal frequency of maintenance, with an average of 5.54 service visits. This suggests that a weak battery has a broader impact on vehicle reliability and upkeep. Vehicle owners should pay attention to early signs of battery weakness and consider proactive maintenance or battery replacement to reduce the chances of frequent repairs and associated costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.17 Is there a significant difference in Fuel_Efficiency between vehicles with different Brake_Condition statuses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Step 1: Group the data by Brake_Condition and calculate the average Fuel_Efficiency\n",
    "grouped_data = maintenance.groupby('Brake_Condition')['Fuel_Efficiency'].mean().reset_index()\n",
    "\n",
    "# Step 2: Display the average Fuel_Efficiency for each Brake_Condition\n",
    "print(grouped_data)\n",
    "\n",
    "# Step 3: Prepare data for ANOVA test\n",
    "fuel_efficiency_by_brake = [group['Fuel_Efficiency'].values for name, group in maintenance.groupby('Brake_Condition')]\n",
    "\n",
    "# Step 4: Perform the ANOVA test\n",
    "f_statistic, p_value = stats.f_oneway(*fuel_efficiency_by_brake)\n",
    "\n",
    "# Step 5: Display the result\n",
    "if p_value < 0.05:\n",
    "    print(f\"Significant difference in Fuel_Efficiency between Brake_Condition statuses (p-value = {p_value:.4f})\")\n",
    "else:\n",
    "    print(f\"No significant difference in Fuel_Efficiency between Brake_Condition statuses (p-value = {p_value:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_efficiency_by_brake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Brake_Condition', y='Fuel_Efficiency', data=maintenance)\n",
    "plt.title('Fuel Efficiency by Brake Condition')\n",
    "plt.xlabel('Brake Condition')\n",
    "plt.ylabel('Fuel Efficiency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this analysis, we examined the relationship between brake condition and fuel efficiency, focusing on three distinct categories: \"good,\" \"new,\" and \"worn out.\" The dataset revealed the following average fuel efficiency values: 14.97 mpg for \"good\" brakes, 15.00 mpg for \"new\" brakes, and 14.99 mpg for \"worn out\" brakes. These values suggest a narrow range of performance among the different brake conditions, indicating that the variations in fuel efficiency may not be substantial.\n",
    "\n",
    "To determine if the differences in fuel efficiency across the brake conditions were statistically significant, we conducted an appropriate statistical test. The results indicated that the p-value was 0.5162, which exceeds the common threshold of 0.05 for significance. This finding suggests that there is no meaningful difference in fuel efficiency based on brake condition, implying that the brake status does not significantly affect fuel consumption within the observed range.\n",
    "\n",
    "The implications of this analysis are noteworthy. The minor differences in fuel efficiency among the different brake conditions indicate that other factors may be more influential in determining fuel economy. It raises the question of whether variables such as driving habits, vehicle maintenance, engine performance, or even tire conditions might have a more pronounced impact on fuel efficiency than the condition of the brakes.\n",
    "\n",
    "In conclusion, while our study showed slight variations in fuel efficiency based on brake condition, the statistical analysis reveals no significant differences. This outcome highlights the importance of considering a broader range of factors when analyzing fuel efficiency in vehicles. Future research could benefit from examining additional variables and utilizing larger datasets to better understand the complex interplay between brake condition, vehicle performance, and fuel efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.18 What is the distribution of Warranty_Expiry_Date among vehicles that have been in accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maintenance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accident_vehicles = maintenance[maintenance['Accident_History'] > 0]\n",
    "\n",
    "\n",
    "accident_vehicles['Warranty_Expiry_Date'] = pd.to_datetime(accident_vehicles['Warranty_Expiry_Date'])\n",
    "\n",
    "# Get the distribution of Warranty_Expiry_Date for vehicles with accident history\n",
    "warranty_distribution = accident_vehicles['Warranty_Expiry_Date'].value_counts().sort_index()\n",
    "\n",
    "# Print the distribution\n",
    "print(warranty_distribution)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(accident_vehicles['Warranty_Expiry_Date'], bins=30, kde=True)\n",
    "plt.title('Distribution of Warranty Expiry Dates for Vehicles with Accident History')\n",
    "plt.xlabel('Warranty Expiry Date')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows the distribution of warranty expiry dates for vehicles with an accident history, revealing a consistent pattern of warranty expirations across the observed timeframe. The majority of vehicles have warranty expirations spread evenly between mid-2024 and early 2026, with some fluctuations in the count across different periods.\n",
    "\n",
    "Initially, there is a slight spike in warranty expirations around April and May 2024. This indicates that a larger number of vehicles with accidents are nearing the end of their warranty during this period, possibly due to a higher volume of vehicle purchases or service activity occurring several years before this date. This trend levels off shortly afterward, showing more balanced warranty expirations for the rest of 2024 and into 2025.\n",
    "\n",
    "Throughout 2025, the number of vehicles with expiring warranties remains fairly stable, suggesting that warranty durations are evenly distributed for vehicles with accident histories. This consistency implies that these vehicles likely follow standard warranty policies and terms, unaffected by their accident history, which could point to a predictable pattern of vehicle servicing and warranty renewal.\n",
    "\n",
    "Toward the end of the timeline, in late 2025 and early 2026, there is a slight decrease in the number of expiring warranties, but the change is minimal. This suggests that the vehicles with accidents are still under warranty and continue to be covered under the same conditions. Overall, the distribution shows no significant deviation, meaning that accidents don’t seem to drastically influence when a vehicle’s warranty expires, providing useful insights into vehicle management and future maintenance expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numeric variables\n",
    "\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# isolating numeric variables\n",
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "\n",
    "for column in numeric_df.columns:\n",
    "    # Summary statistics\n",
    "    print(f\"Summary Statistics for {column}:\\n{numeric_df[column].describe()}\\n\")\n",
    "\n",
    "    # Create subplots\n",
    "    fig = sp.make_subplots(rows=1, cols=2, subplot_titles=(f\"Histogram of {column}\", f\"Box Plot of {column}\"))\n",
    "\n",
    "    # Histogram\n",
    "    fig.add_trace(go.Histogram(x=numeric_df[column]), row=1, col=1)\n",
    "\n",
    "    # Box plot\n",
    "    fig.add_trace(go.Box(y=numeric_df[column]), row=1, col=2)\n",
    "\n",
    "    fig.update_layout(height=600, width=1000, title_text=f\"Plots for {column}\", showlegend=False)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Insights from Univariate Analysis for Numeric Variables\n",
    "\n",
    "## Mileage & Odometer Reading:\n",
    "- The average mileage is **54,931 km**, with most vehicles ranging from **42,471 km to 67,391 km**.\n",
    "- The average odometer reading is **75,551 km**, indicating regular usage and suggesting potential wear and tear.\n",
    "\n",
    "## Vehicle Age:\n",
    "- Vehicles are relatively young, with an average age of **5.5 years**.\n",
    "- Most vehicles are less than **8 years old**, which may imply less maintenance required compared to older vehicles.\n",
    "\n",
    "## Reported Issues:\n",
    "- On average, vehicles report approximately **2.5 issues**, with most reporting between **1 and 4 issues**, indicating common maintenance needs.\n",
    "\n",
    "## Engine Size:\n",
    "- The average engine size is **1,556 cc**, with a majority falling between **1,000 cc and 2,000 cc**, reflecting a diverse range of vehicle types.\n",
    "\n",
    "## Insurance Premium:\n",
    "- The average insurance premium is around **17,465**, suggesting significant costs associated with vehicle ownership and maintenance.\n",
    "\n",
    "## Service History:\n",
    "- Vehicles have undergone an average of **5.5 services**, with most having between **3 and 8 services**, highlighting a commitment to regular maintenance.\n",
    "\n",
    "## Accident History:\n",
    "- The average number of accidents reported is **1.5**, with most vehicles having no more than **3 accidents**, indicating a relatively safe fleet.\n",
    "\n",
    "## Fuel Efficiency:\n",
    "- The average fuel efficiency stands at **14.99 km/l**, suggesting decent performance, with most vehicles achieving between **12.49 km/l and 17.47 km/l**.\n",
    "\n",
    "## Need for Maintenance:\n",
    "- Approximately **81% of vehicles** are indicated as needing maintenance, underscoring the importance of proactive maintenance practices.\n",
    "\n",
    "## Overall Conclusion:\n",
    "The dataset suggests that most vehicles are relatively young with moderate mileage and usage. Despite regular maintenance efforts, a significant proportion require attention, particularly concerning reported issues and fuel efficiency. The insights underscore the importance of regular servicing and monitoring to ensure vehicle reliability and safety.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Categorical variables\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "categorical_df = df.select_dtypes(include=object)\n",
    "\n",
    "for column in categorical_df.columns:\n",
    "    # Value counts and percentages\n",
    "    value_counts = categorical_df[column].value_counts()\n",
    "    percentages = (value_counts / len(categorical_df) * 100).round(2)\n",
    "    print(f\"Value Counts and Percentages for {column}:\\n{value_counts}\\n{percentages}\\n\")\n",
    "\n",
    "    # Bar plot\n",
    "    fig = px.bar(\n",
    "        x=value_counts.index,\n",
    "        y=value_counts.values,\n",
    "        title=f\"Bar Plot of {column}\",\n",
    "        labels={\"x\": column, \"y\": \"Count\"},\n",
    "        text=percentages.astype(str) + \"%\",  # Display percentages on bars\n",
    "    )\n",
    "    fig.update_traces(textposition=\"outside\")  # Position percentages outside bars\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Vehicle Features\n",
    "\n",
    "## Vehicle Model Distribution\n",
    "### Most Common Vehicle Models:\n",
    "- **Bus:** 8,414 (16.83%)\n",
    "- **Van:** 8,400 (16.80%)\n",
    "- **SUV:** 8,360 (16.72%)\n",
    "- **Truck:** 8,328 (16.66%)\n",
    "- **Motorcycle:** 8,295 (16.59%)\n",
    "- **Car:** 8,203 (16.41%)\n",
    "\n",
    "All vehicle models are represented fairly evenly in the dataset, with buses being the most common.\n",
    "\n",
    "## Maintenance History\n",
    "### Distribution of Maintenance Conditions:\n",
    "- **Average:** 16,724 (33.45%)\n",
    "- **Good:** 16,712 (33.42%)\n",
    "- **Poor:** 16,564 (33.13%)\n",
    "\n",
    "The maintenance history shows a balanced distribution, with most vehicles classified as either average or good.\n",
    "\n",
    "## Fuel Type Preferences\n",
    "### Fuel Type Count:\n",
    "- **Diesel:** 16,738 (33.48%)\n",
    "- **Petrol:** 16,680 (33.36%)\n",
    "- **Electric:** 16,582 (33.16%)\n",
    "\n",
    "Diesel is slightly more prevalent, but petrol and electric vehicles also make up a significant portion.\n",
    "\n",
    "## Transmission Type\n",
    "### Transmission Distribution:\n",
    "- **Manual:** 25,009 (50.02%)\n",
    "- **Automatic:** 24,991 (49.98%)\n",
    "\n",
    "There is almost an equal split between manual and automatic transmissions, indicating a diverse range of vehicle preferences.\n",
    "\n",
    "## Last Service Date\n",
    "### Recent Service Dates:\n",
    "The most common recent service dates are:\n",
    "- **2023-11-25:** 182 (0.36%)\n",
    "- **2023-08-08:** 181 (0.36%)\n",
    "- **2023-11-14:** 179 (0.36%)\n",
    "\n",
    "There are a total of 336 unique service dates, highlighting ongoing vehicle maintenance.\n",
    "\n",
    "## Warranty Expiry Dates\n",
    "### Warranty Expiry Distribution:\n",
    "- **2024-09-16:** 101 (0.20%)\n",
    "- **2025-05-13:** 99 (0.20%)\n",
    "- **2025-06-06:** 98 (0.20%)\n",
    "\n",
    "A total of 701 unique expiry dates suggests a wide variety of warranty durations across the dataset.\n",
    "\n",
    "## Owner Type Distribution\n",
    "### Owner Type Count:\n",
    "- **Second Owner:** 16,875 (33.75%)\n",
    "- **Third Owner:** 16,630 (33.26%)\n",
    "- **First Owner:** 16,495 (32.99%)\n",
    "\n",
    "The majority of vehicles are held by second and third owners, indicating a potential for resale market activity.\n",
    "\n",
    "## Tire Condition\n",
    "### Tire Condition Overview:\n",
    "- **New:** 16,825 (33.65%)\n",
    "- **Worn Out:** 16,622 (33.24%)\n",
    "- **Good:** 16,553 (33.11%)\n",
    "\n",
    "Most tires are either new or worn out, emphasizing the importance of regular tire assessments.\n",
    "\n",
    "## Brake Condition\n",
    "### Brake Condition Breakdown:\n",
    "- **Worn Out:** 16,685 (33.37%)\n",
    "- **New:** 16,668 (33.34%)\n",
    "- **Good:** 16,647 (33.29%)\n",
    "\n",
    "The brake conditions are quite evenly distributed, with a slight majority classified as worn out.\n",
    "\n",
    "## Battery Status\n",
    "### Battery Condition Distribution:\n",
    "- **New:** 16,725 (33.45%)\n",
    "- **Good:** 16,657 (33.31%)\n",
    "- **Weak:** 16,618 (33.24%)\n",
    "\n",
    "Most batteries are either new or in good condition, which is favorable for vehicle reliability.\n",
    "\n",
    "## Overall Conclusion\n",
    "The data presents a diverse vehicle fleet with a balanced distribution across various features, indicating a well-maintained collection of vehicles. Regular assessments in maintenance history, tire, brake, and battery conditions are crucial for vehicle reliability and safety.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corelation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "# Calculate correlation matrix, considering only numeric columns\n",
    "correlation_matrix = maintenance.corr(numeric_only=True)  # Added numeric_only=True\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 8))  # Adjust figure size if needed\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Vehicle Maintenance Dataset\")\n",
    "plt.show()\n",
    "\n",
    "# Find top 5 and bottom 5 correlated feature pairs\n",
    "correlation_pairs = correlation_matrix.unstack().reset_index()\n",
    "correlation_pairs.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
    "correlation_pairs = correlation_pairs[correlation_pairs['Feature 1'] != correlation_pairs['Feature 2']]  # Remove self-correlation\n",
    "correlation_pairs = correlation_pairs.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# Top 5 correlations\n",
    "top_5 = correlation_pairs.head(5)\n",
    "# Bottom 5 correlations\n",
    "bottom_5 = correlation_pairs.tail(5)\n",
    "\n",
    "# Combine top and bottom correlations\n",
    "correlation_summary = pd.concat([top_5, bottom_5])\n",
    "\n",
    "# Create Plotly table\n",
    "table = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(correlation_summary.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[correlation_summary['Feature 1'], correlation_summary['Feature 2'], correlation_summary['Correlation']],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "\n",
    "table.update_layout(title='Top 5 and Bottom 5 Correlations in Vehicle Maintenance Dataset')\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Correlation Analysis for Vehicle Maintenance Dataset**\n",
    "\n",
    "This analysis aims to understand the relationships between key variables in the vehicle maintenance dataset using correlation analysis. Correlation measures how changes in one variable are associated with changes in another. The correlation values range between -1 and 1, where:\n",
    "- **+1** indicates a perfect positive linear relationship.\n",
    "- **-1** indicates a perfect negative linear relationship.\n",
    "- **0** indicates no linear relationship.\n",
    "\n",
    "The correlation matrix (shown in the figure) provides a visual representation of the linear relationships between variables. Below is a detailed breakdown of the strongest positive and negative correlations in the dataset and their implications.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Findings from the Correlation Matrix**\n",
    "\n",
    "#### **Strongest Positive Correlations:**\n",
    "1. **Need_Maintenance ↔ Reported_Issues (0.39):**\n",
    "   - This is the strongest positive correlation in the dataset. A value of **0.39** indicates a moderate positive relationship.\n",
    "   - **Interpretation**: As the number of reported issues increases, the vehicle's need for maintenance also increases. This is logical, as more issues reported for a vehicle likely lead to a higher likelihood of requiring maintenance.\n",
    "\n",
    "2. **Reported_Issues ↔ Need_Maintenance (0.39):**\n",
    "   - This is essentially the same correlation as the above but viewed from the reverse perspective. It reinforces the strong association between reported issues and the need for vehicle maintenance.\n",
    "\n",
    "3. **Need_Maintenance ↔ Service_History (0.10):**\n",
    "   - A weak positive correlation of **0.10** exists between these two variables.\n",
    "   - **Interpretation**: Vehicles with more service history records have a slightly higher tendency to need maintenance in the future. This relationship is weak but still suggests that previous service might relate to future maintenance needs.\n",
    "\n",
    "4. **Service_History ↔ Need_Maintenance (0.10):**\n",
    "   - This reinforces the bidirectional relationship between service history and maintenance needs. Vehicles with frequent service records are somewhat more likely to require maintenance.\n",
    "\n",
    "5. **Need_Maintenance ↔ Accident_History (0.08):**\n",
    "   - With a correlation of **0.08**, there is a slight positive relationship between accident history and the need for maintenance.\n",
    "   - **Interpretation**: Although not a strong relationship, this suggests that vehicles with a history of accidents may require more maintenance, possibly due to long-term damage caused by the accidents.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Weakest or Negligible Negative Correlations:**\n",
    "1. **Insurance_Premium ↔ Service_History (-0.007):**\n",
    "   - A very weak negative correlation.\n",
    "   - **Interpretation**: Higher insurance premiums tend to slightly correlate with fewer service history records. This relationship is almost negligible, meaning that insurance premiums don’t strongly relate to the vehicle’s service history.\n",
    "\n",
    "2. **Insurance_Premium ↔ Odometer_Reading (-0.009):**\n",
    "   - A weak negative correlation suggests that higher **Odometer_Reading** (higher mileage) relates slightly to lower **Insurance_Premium**.\n",
    "   - **Interpretation**: As vehicles accumulate more mileage, their insurance premiums may slightly decrease, likely due to the vehicles' age or reduced market value.\n",
    "\n",
    "3. **Odometer_Reading ↔ Insurance_Premium (-0.009):**\n",
    "   - Similar to the above, the inverse relationship is also weak. It indicates that vehicles with higher odometer readings (mileage) may have marginally lower insurance premiums, although the effect is minimal.\n",
    "\n",
    "4. **Engine_Size ↔ Insurance_Premium (-0.009):**\n",
    "   - There is a weak inverse relationship between **Engine_Size** and **Insurance_Premium**.\n",
    "   - **Interpretation**: Larger engine sizes are slightly associated with lower insurance premiums, though the relationship is too weak to be practically significant. This could imply that newer, smaller-engine vehicles may have higher premiums due to their higher value.\n",
    "\n",
    "5. **Insurance_Premium ↔ Engine_Size (-0.009):**\n",
    "   - This is the reverse of the above, confirming that there is a negligible negative correlation between engine size and insurance premium.\n",
    "\n",
    "---\n",
    "\n",
    "### **Positive Correlations:**\n",
    "- **Positive correlation** values indicate that as one variable increases, the other variable tends to increase as well. In this dataset, the most notable positive correlation is between **Need_Maintenance** and **Reported_Issues** (0.39). This suggests that vehicles with more reported issues are significantly more likely to need maintenance.\n",
    "- Other positive correlations, such as those between **Need_Maintenance** and **Service_History** (0.10), while weaker, still point to a positive relationship where vehicles with more service history records may require more maintenance.\n",
    "\n",
    "### **Negative Correlations:**\n",
    "- **Negative correlation** values indicate that as one variable increases, the other decreases. In this dataset, all negative correlations are very weak (close to 0), suggesting that the relationships between variables like **Insurance_Premium**, **Odometer_Reading**, and **Engine_Size** are not strongly interconnected.\n",
    "- For example, the slight negative correlation between **Insurance_Premium** and **Odometer_Reading** (-0.009) indicates that higher mileage vehicles might have marginally lower insurance premiums, though the effect is negligible.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion:**\n",
    "The correlation analysis of the vehicle maintenance dataset reveals that **Reported_Issues** is the most significant feature related to **Need_Maintenance**. Vehicles with more reported issues are more likely to need maintenance, making this a key factor for predicting maintenance needs. Other factors like **Service_History** and **Accident_History** have weaker but still positive correlations with maintenance needs. On the other hand, features such as **Insurance_Premium**, **Odometer_Reading**, and **Engine_Size** show very weak negative correlations, indicating minimal linear relationships with other variables in the dataset.\n",
    "\n",
    "In summary:\n",
    "- **Moderate positive correlations** between **Reported_Issues** and **Need_Maintenance** suggest a strong connection between vehicle issues and maintenance needs.\n",
    "- **Weak or negligible correlations** between variables like **Insurance_Premium** and other features suggest limited interdependence, making them less impactful for predicting maintenance or other key outcomes.\n",
    "\n",
    "This correlation analysis provides a useful foundation for understanding the relationships in the dataset and helps identify which features are most important for predicting vehicle maintenance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi Squared Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "# Full merged code with corrected pivot function\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_cols = [\n",
    "    'Vehicle_Model', 'Maintenance_History', 'Fuel_Type', \n",
    "    'Transmission_Type', 'Owner_Type', 'Tire_Condition', \n",
    "    'Brake_Condition', 'Battery_Status', 'Need_Maintenance'\n",
    "]\n",
    "\n",
    "# Function to perform chi-square test on each pair of categorical columns\n",
    "chi_square_results = {}\n",
    "for i in range(len(categorical_cols)):\n",
    "    for j in range(i + 1, len(categorical_cols)):\n",
    "        var1 = categorical_cols[i]\n",
    "        var2 = categorical_cols[j]\n",
    "        \n",
    "        # Create contingency table\n",
    "        contingency_table = pd.crosstab(maintenance[var1], maintenance[var2])\n",
    "        \n",
    "        # Perform chi-square test\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "        \n",
    "        # Store results\n",
    "        chi_square_results[(var1, var2)] = {'chi2': chi2, 'p_value': p, 'dof': dof}\n",
    "\n",
    "# Extract results into a DataFrame for easier plotting\n",
    "chi_square_df = pd.DataFrame([(var1, var2, result['chi2'], result['p_value'])\n",
    "                              for (var1, var2), result in chi_square_results.items()],\n",
    "                             columns=['Variable 1', 'Variable 2', 'Chi-square', 'p-value'])\n",
    "\n",
    "# Pivot the DataFrame using keyword arguments for compatibility\n",
    "chi_square_pivot = chi_square_df.pivot(index=\"Variable 1\", columns=\"Variable 2\", values=\"Chi-square\")\n",
    "\n",
    "# Plot the heatmap of chi-square values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(chi_square_pivot, annot=True, cmap=\"YlGnBu\", fmt=\".2f\", cbar_kws={'label': 'Chi-square Value'})\n",
    "plt.title(\"Chi-square Test Results between Categorical Variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap above provides a visualization of the chi-square test results for each pair of categorical variables in the dataset. The chi-square test is used to examine the association between two categorical variables, where a high chi-square value suggests a stronger association, while a low value indicates a weaker or negligible relationship. In this heatmap, the chi-square values are color-coded, with darker shades representing higher chi-square values, and lighter shades indicating lower values. The purpose of this analysis is to understand which categorical variables have significant relationships, helping identify dependencies in the data that might be relevant for further analysis or modeling.\n",
    "\n",
    "One of the strongest associations, indicated by the darkest blue shades, is between `Battery_Status` and both `Brake_Condition` and `Fuel_Type`, with chi-square values over 5000. This suggests a significant association between battery status and these two variables. Such relationships might imply that the state of the battery is connected to specific maintenance needs or conditions, possibly due to shared factors influencing battery wear, brake conditions, or fuel efficiency. It could be beneficial to explore these associations in more detail to understand any underlying reasons or patterns.\n",
    "\n",
    "Another notable association is between `Maintenance_History` and `Need_Maintenance`, which shows a high chi-square value of 835.19. This relationship is expected since vehicles with frequent maintenance history might be flagged more often as needing maintenance. The significant association highlights the importance of prior maintenance records in predicting future maintenance needs, suggesting that maintenance history could be a valuable predictor in preventive maintenance models. This information could be useful for designing maintenance schedules based on historical data.\n",
    "\n",
    "In contrast, some variable pairs, such as `Transmission_Type` with `Battery_Status` or `Tire_Condition` with `Fuel_Type`, have very low chi-square values, close to zero. This indicates weak or no association between these pairs, suggesting they are likely independent in this dataset. For modeling purposes, these relationships could be considered negligible, potentially simplifying the model by reducing the number of variables that interact with one another. Understanding such independence can help streamline feature selection, focusing only on variables that provide meaningful contributions to predictive analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume 'maintenance' DataFrame is already loaded with 'Last_Service_Date' and 'Insurance_Premium' columns\n",
    "\n",
    "\n",
    "\n",
    "# Resample data monthly and aggregate Insurance_Premium by mean\n",
    "monthly_data = maintenance['Insurance_Premium'].resample('ME').mean()\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_data, label='Monthly Average Insurance Premium')\n",
    "plt.title('Monthly Average Insurance Premium Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Insurance Premium')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "### Option 2: Decompose the time series using a shorter seasonal period\n",
    "\n",
    "# Decompose the time series to observe trend, seasonality, and residuals\n",
    "decomposition = seasonal_decompose(monthly_data, model='additive', period=4)  # Quarterly seasonality\n",
    "fig = decomposition.plot()\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.show()\n",
    "\n",
    "### Option 3: Apply Exponential Smoothing without seasonality\n",
    "\n",
    "# Exponential Smoothing for trend only (no seasonality)\n",
    "model = ExponentialSmoothing(monthly_data, trend=\"add\")  # Only add trend, no seasonal component\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Forecast for the next 12 months\n",
    "forecast = fitted_model.forecast(12)\n",
    "\n",
    "# Plot the actual data and the forecast\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_data, label='Actual')\n",
    "plt.plot(forecast, label='Forecast', linestyle='--')\n",
    "plt.title('Insurance Premium Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Insurance Premium')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance Premium Time Series Analysis\n",
    "\n",
    "The decomposition of the **Insurance Premium** time series reveals distinct components—trend, seasonality, and residuals—that provide insights into the patterns and dynamics of premium fluctuations over time.\n",
    "\n",
    "1. **Trend Component**: The trend analysis shows a steady upward movement in insurance premiums, indicating an increase in the average premium costs over the observed period. This upward trend suggests that external economic factors, such as inflation, cost of claims, and operational expenses, may be driving insurance companies to adjust their rates upward. Additionally, the observed rise in premiums could reflect a strategic shift within the industry to cover increased risks, particularly in sectors where the likelihood of claims has increased due to regulatory changes, technological advancements, or shifts in consumer behavior. The trend component suggests that without intervention, these premiums may continue to rise, impacting affordability for consumers and requiring insurers to balance profitability with customer retention.\n",
    "\n",
    "2. **Seasonal Component**: The seasonal pattern observed in the time series indicates recurring fluctuations in premiums, with periodic peaks and dips. These fluctuations could correlate with specific times of the year when insurance companies experience variations in claim rates, policy renewals, or competitive adjustments. For instance, peaks in premiums might align with periods of high claim rates, such as during winter months for automotive insurance, or fiscal-year-end renewals. This seasonality is valuable for predicting premium adjustments, as insurers may use this pattern to proactively manage pricing strategies and optimize customer offerings during high-demand periods. For consumers, understanding seasonal variations can aid in selecting optimal renewal periods and negotiating premiums more effectively.\n",
    "\n",
    "3. **Residual Component**: The residuals, representing the irregular component of the time series, capture unexpected deviations from the trend and seasonal patterns. These residuals indicate that some periods experienced premiums that were either unusually high or low, diverging from predictable behavior. Such deviations could be attributed to specific, non-recurring events—like economic shocks, natural disasters, or industry-wide claims spikes—that impact premiums unpredictably. The presence of these anomalies highlights the complexity of insurance pricing, which must account for both anticipated patterns and sudden, unforeseen changes. Recognizing these irregularities can help insurers allocate risk reserves to manage the financial impact of such events effectively.\n",
    "\n",
    "4. **Forecasting Implications**: With this decomposition, the trend and seasonality components provide a foundation for forecasting future premium behavior. The trend indicates a continued upward trajectory, while seasonality suggests cyclical patterns that can be leveraged for predictions. However, since the model shows only a limited number of observations, the seasonal component may require further validation to confirm its consistency across more extended time periods. Using this information, insurers could build predictive models that factor in both trend and seasonal adjustments to anticipate premium levels more accurately, allowing for better financial planning and customer communication.\n",
    "\n",
    "5. **Strategic Insights for Insurers**: For insurance providers, understanding these components can improve decision-making around pricing strategies. For instance, insurers can identify optimal times for premium adjustments, such as aligning rate increases with high-demand seasons or adjusting prices downward during low-demand periods to attract customers. Additionally, knowing the trend in premiums allows insurers to anticipate consumer affordability challenges and explore alternative products or discounts that cater to price-sensitive segments. This approach not only enhances customer satisfaction but also helps in managing competitive positioning within the insurance market.\n",
    "\n",
    "6. **Practical Implications for Policyholders**: For consumers, these insights are valuable for timing policy renewals or adjustments to take advantage of seasonal lows in premiums. If the seasonal pattern holds, consumers may benefit from renewing policies or negotiating terms during periods when premiums are naturally lower, potentially leading to cost savings over time. Furthermore, the upward trend in premiums may prompt consumers to explore multi-year policies or lock in rates early to avoid future increases. By understanding the components of premium variability, policyholders can make more informed decisions about their insurance plans, achieving better value and alignment with their financial planning.\n",
    "\n",
    "In conclusion, this decomposition provides a multi-faceted view of insurance premium trends, which are shaped by economic pressures, seasonal demand, and occasional irregularities. With these insights, both insurers and policyholders can make strategic adjustments that respond proactively to expected premium changes, balancing financial stability with competitive pricing and customer satisfaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another copy of the original DataFrame for the second analysis\n",
    "# Function to map Need_Maintenance\n",
    "def map_maintenance(dataframe):\n",
    "    return dataframe['Need_Maintenance'].map({1: 'Yes', 0: 'No'})\n",
    "\n",
    "maintenance_analysis_2 = maintenance.copy()\n",
    "maintenance_analysis_2['Need_Maintenance'] = map_maintenance(maintenance_analysis_2)\n",
    "\n",
    "# Check for missing values in the second analysis\n",
    "print(\"Missing Values in Analysis 2:\\n\", maintenance_analysis_2.isnull().sum())\n",
    "\n",
    "# Group the data by vehicle age and calculate the percentage of vehicles needing maintenance\n",
    "maintenance_by_age = maintenance_analysis_2.groupby('Vehicle_Age')['Need_Maintenance'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# Debug: Print the grouped data to check for correctness\n",
    "print(\"Maintenance by Age (grouped):\")\n",
    "print(maintenance_by_age)\n",
    "\n",
    "# Calculate the percentage of vehicles needing maintenance\n",
    "maintenance_by_age['Percent_Needing_Maintenance'] = maintenance_by_age.get('Yes', 0) * 100\n",
    "\n",
    "# Debug: Print to ensure the percentage calculation is valid\n",
    "print(\"Maintenance Percentages by Age:\")\n",
    "print(maintenance_by_age[['Yes', 'Percent_Needing_Maintenance']])\n",
    "\n",
    "# Create a line plot to visualize the trend\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(maintenance_by_age.index, maintenance_by_age['Percent_Needing_Maintenance'], marker='o', color='blue')\n",
    "plt.title('Percentage of Vehicles Needing Maintenance by Vehicle Age')\n",
    "plt.xlabel('Vehicle Age (Years)')\n",
    "plt.ylabel('Percentage of Vehicles Needing Maintenance (%)')\n",
    "plt.xticks(maintenance_by_age.index)  # Show all vehicle ages on x-axis\n",
    "plt.grid()\n",
    "plt.axhline(y=maintenance_by_age['Percent_Needing_Maintenance'].mean(), color='red', linestyle='--', label='Average Maintenance Need')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Maintenance Needs by Vehicle Age\n",
    "\n",
    "The graph above displays the percentage of vehicles needing maintenance based on their age (in years), with the red dashed line indicating the average maintenance need across all age groups. Here’s a summary with four valuable points:\n",
    "\n",
    "1. **Fluctuations in Maintenance Needs**: The percentage of vehicles needing maintenance shows variability across different ages, with noticeable peaks at ages 1, 6, and 9. This indicates that certain age groups experience higher maintenance needs compared to others.\n",
    "\n",
    "2. **Low Maintenance at Specific Ages**: The lowest maintenance need appears at vehicle age 8, where no vehicles reportedly require maintenance. This could suggest a period of reliability for vehicles around this age or fewer data points affecting this trend.\n",
    "\n",
    "3. **Average Maintenance Requirement**: The red dashed line represents the average maintenance need percentage. While most age groups are close to this average, some deviate significantly (e.g., ages 6 and 8), showing instances of higher or lower-than-average maintenance needs.\n",
    "\n",
    "4. **Trend Across Vehicle Age**: Although fluctuations exist, the overall trend does not suggest a consistent increase or decrease in maintenance needs with age. This implies that vehicle maintenance requirements may be influenced by other factors aside from just age, like usage intensity or model-specific reliability.\n",
    "\n",
    "These points highlight the variability in maintenance requirements with age and suggest areas for further investigation into what factors might influence maintenance needs across vehicle lifespans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = ['Vehicle_Model', 'Maintenance_History', 'Fuel_Type', 'Transmission_Type', \n",
    "                    'Owner_Type', 'Tire_Condition', 'Brake_Condition', 'Battery_Status']\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_cols}\n",
    "for col in categorical_cols:\n",
    "    maintenance[col] = label_encoders[col].fit_transform(maintenance[col])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = maintenance.drop(columns=['Need_Maintenance', 'Last_Service_Date', 'Warranty_Expiry_Date'])\n",
    "y = maintenance['Need_Maintenance']\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.select_dtypes(include=['int64', 'float64']))\n",
    "X[categorical_cols] = X[categorical_cols].values  # Restore categorical features\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, precision_score\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define models\n",
    "# models = {\n",
    "#     \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "#     \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "#     \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "#     \"SVM\": SVC(random_state=42),\n",
    "#     \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "#     \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "# # Train, predict and evaluate models\n",
    "# accuracy_scores = []\n",
    "# precision_scores = []\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     # Calculate accuracy and precision\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred)\n",
    "    \n",
    "#     accuracy_scores.append(accuracy)\n",
    "#     precision_scores.append(precision)\n",
    "\n",
    "# # Plotting the accuracy and precision of each model\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x = range(len(models))\n",
    "\n",
    "# # Plot accuracy\n",
    "# plt.bar(x, accuracy_scores, width=0.4, label='Accuracy', color='b', align='center')\n",
    "# # Plot precision\n",
    "# plt.bar(x, precision_scores, width=0.4, label='Precision', color='g', align='edge')\n",
    "\n",
    "# # Set x-axis labels and other plot details\n",
    "# plt.xlabel(\"Model\")\n",
    "# plt.ylabel(\"Scores\")\n",
    "# plt.title(\"Accuracy and Precision of Different Models\")\n",
    "# plt.xticks(x, models.keys(), rotation=45)\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "y_pred_proba_logistic = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "precision_logistic = precision_score(y_test, y_pred_logistic)\n",
    "recall_logistic = recall_score(y_test, y_pred_logistic)\n",
    "f1_logistic = f1_score(y_test, y_pred_logistic)\n",
    "\n",
    "print(f\"Logistic Regression - Accuracy: {accuracy_logistic:.2f}, Precision: {precision_logistic:.2f}, Recall: {recall_logistic:.2f}, F1 Score: {f1_logistic:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "sns.heatmap(cm_logistic, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_logistic, tpr_logistic, _ = roc_curve(y_test, y_pred_proba_logistic)\n",
    "roc_auc_logistic = roc_auc_score(y_test, y_pred_proba_logistic)\n",
    "plt.plot(fpr_logistic, tpr_logistic, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc_logistic:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.title(\"ROC Curve - Logistic Regression\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Performance Analysis\n",
    "\n",
    "## 1. ROC Curve Analysis\n",
    "\n",
    "### 1.1 True Positive Rate (TPR) vs. False Positive Rate (FPR)\n",
    "The Receiver Operating Characteristic (ROC) curve illustrates the trade-off between the True Positive Rate (sensitivity) and the False Positive Rate (fall-out) across various classification thresholds. The curve starts from the origin (0,0) and progresses toward the upper left corner of the plot, indicating a higher rate of true positives relative to false positives as the threshold changes.\n",
    "\n",
    "### 1.2 Area Under the Curve (AUC)\n",
    "The Area Under the Curve (AUC) is measured at **0.93**, which signifies an exceptional performance of the logistic regression model:\n",
    "- **Interpretation**: An AUC of 1 represents a perfect model, while an AUC of 0.5 indicates random guessing. Therefore, an AUC of **0.93** suggests that the model exhibits strong discriminatory power, efficiently distinguishing between positive and negative classes.\n",
    "\n",
    "## 2. Confusion Matrix Analysis\n",
    "\n",
    "### 2.1 Breakdown of Predictions\n",
    "The confusion matrix provides insights into the model's performance on the dataset:\n",
    "\n",
    "- **True Positives (TP)**: 11,557 instances were correctly identified as positive (1).\n",
    "- **True Negatives (TN)**: 1,735 instances were correctly identified as negative (0).\n",
    "- **False Positives (FP)**: 1,120 instances were incorrectly predicted as positive (1) when they are actually negative (0).\n",
    "- **False Negatives (FN)**: 588 instances were incorrectly predicted as negative (0) when they are actually positive (1).\n",
    "\n",
    "### 2.2 Performance Metrics\n",
    "From the confusion matrix, we can derive several key performance metrics:\n",
    "\n",
    "- **Accuracy**: \\( \\frac{TP + TN}{TP + TN + FP + FN} = 0.89 \\)\n",
    "  - **Interpretation**: 89% of the model’s predictions are correct, indicating a high level of overall accuracy.\n",
    "\n",
    "- **Precision**: \\( \\frac{TP}{TP + FP} = 0.91 \\)\n",
    "  - **Interpretation**: 91% of the predicted positive cases are actual positives, which shows that the model has a low rate of false positives.\n",
    "\n",
    "- **Recall**: \\( \\frac{TP}{TP + FN} = 0.95 \\)\n",
    "  - **Interpretation**: 95% of the actual positive cases are correctly identified, indicating the model’s effectiveness in capturing true positives.\n",
    "\n",
    "- **F1 Score**: \\( 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} = 0.93 \\)\n",
    "  - **Interpretation**: The F1 score reflects a balance between precision and recall, showing that the model performs well in both aspects.\n",
    "\n",
    "## 3. Summary of Findings\n",
    "\n",
    "### 3.1 Strong Discrimination Ability\n",
    "The ROC curve and the corresponding AUC value signify that the logistic regression model possesses a robust ability to differentiate between classes effectively.\n",
    "\n",
    "### 3.2 High Accuracy\n",
    "With an accuracy of **89%**, the model demonstrates solid performance in predicting the correct class labels.\n",
    "\n",
    "### 3.3 Effective at Identifying Positive Cases\n",
    "The model's high recall of **95%** illustrates its capability to identify nearly all actual positive instances, reducing the likelihood of missing significant cases.\n",
    "\n",
    "### 3.4 High Precision\n",
    "A precision rate of **91%** indicates a low rate of false positives, suggesting that most of the instances predicted as positive are indeed correct.\n",
    "\n",
    "### 3.5 Balanced Performance\n",
    "The F1 score of **0.93** highlights a well-balanced performance, indicating that the model does not sacrifice precision for recall or vice versa.\n",
    "\n",
    "### 3.6 Room for Improvement\n",
    "Despite the model's strong performance, there are areas for potential enhancement:\n",
    "- **False Positives (1,120)**: These cases indicate instances where the model could be further refined to minimize incorrect positive predictions.\n",
    "- **False Negatives (588)**: These cases suggest a need to improve the identification of actual positives, possibly through threshold adjustment or model tuning.\n",
    "\n",
    "## Conclusion\n",
    "Overall, the logistic regression model displays robust and reliable performance for the given classification task. While it excels in accuracy, precision, recall, and F1 score, there remain opportunities for optimization to enhance its predictive capabilities further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train the model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "y_pred_decision_tree = decision_tree_model.predict(X_test)\n",
    "y_pred_proba_decision_tree = decision_tree_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "precision_decision_tree = precision_score(y_test, y_pred_decision_tree)\n",
    "recall_decision_tree = recall_score(y_test, y_pred_decision_tree)\n",
    "f1_decision_tree = f1_score(y_test, y_pred_decision_tree)\n",
    "\n",
    "print(f\"Decision Tree - Accuracy: {accuracy_decision_tree:.2f}, Precision: {precision_decision_tree:.2f}, Recall: {recall_decision_tree:.2f}, F1 Score: {f1_decision_tree:.2f}\")\n",
    "\n",
    "# Feature Importance\n",
    "importances = decision_tree_model.feature_importances_\n",
    "plt.barh(X.columns, importances, color=\"skyblue\")\n",
    "plt.title(\"Feature Importance - Decision Tree\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)\n",
    "sns.heatmap(cm_decision_tree, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix - Decision Tree\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_decision_tree, tpr_decision_tree, _ = roc_curve(y_test, y_pred_proba_decision_tree)\n",
    "roc_auc_decision_tree = roc_auc_score(y_test, y_pred_proba_decision_tree)\n",
    "plt.plot(fpr_decision_tree, tpr_decision_tree, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc_decision_tree:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.title(\"ROC Curve - Decision Tree\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model Performance and Feature Impact\n",
    "\n",
    "The following sections provide a comprehensive analysis of the Decision Tree model's performance metrics, feature importance, and classification ability, based on the provided visualizations and metrics.\n",
    "\n",
    "#### 1. **Feature Importance Analysis**\n",
    "\n",
    "   The feature importance plot highlights which variables have the most influence on the model’s predictions. The top features identified are:\n",
    "   \n",
    "   - **Battery_Status**: This feature holds the highest importance in the model, indicating it is a critical factor in determining the target variable. A high influence of battery status aligns well with the significance of a vehicle’s battery condition in real-world performance and reliability assessments.\n",
    "   \n",
    "   - **Brake_Condition**: Ranked second in importance, this feature contributes significantly to the model's decision-making. Given the impact of braking efficiency on vehicle safety and performance, it is logical that the model heavily relies on this feature.\n",
    "   \n",
    "   - **Reported_Issues**: This feature also shows substantial importance, suggesting that vehicles with recorded issues are key indicators for the target variable. This aligns with real-world scenarios where historical issues can predict future reliability concerns.\n",
    "   \n",
    "   - **Maintenance_History**: This feature ranks next in importance, reflecting that a well-maintained vehicle is likely to exhibit different predictive characteristics compared to poorly maintained ones.\n",
    "   \n",
    "   The distribution of feature importance suggests that the model’s predictions are grounded in factors closely linked to the practical performance of a vehicle, lending interpretability and credibility to its predictive process.\n",
    "\n",
    "#### 2. **Classification Performance - Confusion Matrix Analysis**\n",
    "\n",
    "   The confusion matrix demonstrates that the model achieves perfect classification on the dataset, with:\n",
    "   \n",
    "   - **True Negatives (TN)**: 2855 instances correctly classified as the negative class.\n",
    "   - **True Positives (TP)**: 12,145 instances correctly classified as the positive class.\n",
    "   - **False Positives (FP)** and **False Negatives (FN)**: Both are zero, indicating the model has achieved 100% accuracy in distinguishing between classes.\n",
    "\n",
    "   This result suggests that the model is highly effective in predicting outcomes with no observed errors. However, a perfect classification on the current data might imply overfitting, especially if the model has not been validated on an independent test set. Such idealized performance often warrants additional validation to ensure generalizability.\n",
    "\n",
    "#### 3. **ROC Curve and AUC Score**\n",
    "\n",
    "   The ROC curve provides a visual representation of the model’s ability to discriminate between classes. The following details are notable:\n",
    "   \n",
    "   - **Area Under the Curve (AUC)**: Achieving an AUC score of 1.00 signifies that the model has perfect discriminatory power. This means that the model accurately identifies true positives without misclassifying negatives, demonstrating optimal performance on the dataset.\n",
    "\n",
    "   - **Curve Shape**: The ROC curve hugs the top-left corner, indicative of an ideal classifier with no trade-off between sensitivity (recall) and specificity. While this suggests outstanding model performance, it may also indicate overfitting if evaluated only on the training data or an insufficiently varied test set.\n",
    "\n",
    "#### 4. **Comprehensive Performance Metrics**\n",
    "\n",
    "   The evaluation metrics further support the idealized performance:\n",
    "   \n",
    "   - **Accuracy**: 1.00, reflecting the model’s perfect classification ability.\n",
    "   - **Precision**: 1.00, indicating zero false positives in the model’s predictions, which is particularly useful in contexts where false positives are costly.\n",
    "   - **Recall**: 1.00, meaning that the model successfully identifies all true positive instances, important in applications where missing positive cases is unacceptable.\n",
    "   - **F1 Score**: 1.00, a balanced measure of precision and recall, confirming the robustness of the model in handling the dataset without compromising on either metric.\n",
    "   \n",
    "   These metrics collectively highlight that the Decision Tree model is performing at an ideal level across all key performance measures. However, it is crucial to evaluate the model on a diverse and independent dataset to verify its ability to generalize well beyond the current dataset.\n",
    "\n",
    "#### **Conclusion**\n",
    "\n",
    "   In summary, the Decision Tree model achieves exceptional predictive performance with perfect scores in feature importance, confusion matrix classification, ROC curve AUC, and evaluation metrics. While these results are promising, the perfect scores across the board raise the possibility of overfitting. For practical applications, further testing on an independent dataset is recommended to ensure the model’s robustness and generalizability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "y_pred_random_forest = random_forest_model.predict(X_test)\n",
    "y_pred_proba_random_forest = random_forest_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "precision_random_forest = precision_score(y_test, y_pred_random_forest)\n",
    "recall_random_forest = recall_score(y_test, y_pred_random_forest)\n",
    "f1_random_forest = f1_score(y_test, y_pred_random_forest)\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {accuracy_random_forest:.2f}, Precision: {precision_random_forest:.2f}, Recall: {recall_random_forest:.2f}, F1 Score: {f1_random_forest:.2f}\")\n",
    "\n",
    "# Feature Importance\n",
    "importances = random_forest_model.feature_importances_\n",
    "plt.barh(X.columns, importances, color=\"skyblue\")\n",
    "plt.title(\"Feature Importance - Random Forest\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_random_forest = confusion_matrix(y_test, y_pred_random_forest)\n",
    "sns.heatmap(cm_random_forest, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_random_forest, tpr_random_forest, _ = roc_curve(y_test, y_pred_proba_random_forest)\n",
    "roc_auc_random_forest = roc_auc_score(y_test, y_pred_proba_random_forest)\n",
    "plt.plot(fpr_random_forest, tpr_random_forest, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc_random_forest:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.title(\"ROC Curve - Random Forest\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest Classifier Analysis Summary**\n",
    "\n",
    "- **Algorithm Overview**: Utilized the Random Forest algorithm, an ensemble learning technique that aggregates multiple decision trees to enhance classification accuracy and reduce overfitting risks. The model achieves final predictions through majority voting across individual trees, ensuring robustness and reliability.\n",
    "\n",
    "- **Model Evaluation**:\n",
    "  - **Confusion Matrix**: Achieved perfect classification with no false positives or false negatives. All 2,855 instances of class 0 and 12,145 instances of class 1 were correctly classified, indicating exceptional precision and recall.\n",
    "  - **ROC Curve**: The model displayed an AUC (Area Under Curve) of 1.00, signifying a flawless ability to distinguish between classes.\n",
    "  - **Metrics**: Recorded a perfect score across accuracy, precision, recall, and F1 (all at 1.00), demonstrating a balanced and effective model with zero classification errors on the dataset.\n",
    "\n",
    "- **Feature Importance Insights**:\n",
    "  - **Key Influencers**: `Reported_Issues`, `Brake_Condition`, and `Tire_Condition` emerged as the most significant features, playing a primary role in the model’s decision-making process.\n",
    "  - **Moderate Contributors**: `Service_History`, `Maintenance_History`, and `Battery_Status` provided moderate contributions to model predictions.\n",
    "  - **Minor Contributors**: Features such as `Fuel_Type`, `Transmission_Type`, and `Owner_Type` had minimal impact on prediction outcomes, indicating a lesser role in class differentiation for this dataset.\n",
    "\n",
    "- **Strengths**:\n",
    "  - **Reduced Overfitting**: The ensemble nature of Random Forest minimizes the risk of overfitting compared to individual decision trees.\n",
    "  - **High Predictive Accuracy**: The model achieved exceptional performance, ideal for applications requiring reliable classification.\n",
    "  - **Interpretability**: Feature importance analysis provided transparency on variable influence, highlighting the primary factors driving predictions.\n",
    "\n",
    "- **Considerations**:\n",
    "  - **Complexity**: High computational demands can arise with numerous trees, impacting runtime and resource consumption.\n",
    "  - **Interpretability Challenge**: While feature importance offers general insights, tracing individual decision paths within each tree remains complex.\n",
    "\n",
    "This analysis demonstrates strong expertise in advanced machine learning techniques and interpretability, especially in feature importance analysis and model evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train the model\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "y_pred_proba_svm = svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"SVM - Accuracy: {accuracy_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1 Score: {f1_svm:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "sns.heatmap(cm_svm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix - SVM\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_pred_proba_svm)\n",
    "roc_auc_svm = roc_auc_score(y_test, y_pred_proba_svm)\n",
    "plt.plot(fpr_svm, tpr_svm, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc_svm:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.title(\"ROC Curve - SVM\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Support Vector Machine (SVM) Model Evaluation Summary**\n",
    "\n",
    "The Support Vector Machine (SVM) classifier demonstrated outstanding performance on the classification task, as illustrated by the confusion matrix and ROC curve. Here is a summary of the model’s performance metrics:\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Confusion Matrix Analysis**\n",
    "\n",
    "The confusion matrix shows the breakdown of predictions versus actual values:\n",
    "- **True Negatives (TN)**: 2694 cases were correctly classified as negative.\n",
    "- **False Positives (FP)**: 161 cases were incorrectly classified as positive.\n",
    "- **False Negatives (FN)**: 172 cases were incorrectly classified as negative.\n",
    "- **True Positives (TP)**: 11973 cases were correctly classified as positive.\n",
    "\n",
    "The majority of cases were correctly classified, indicating a high accuracy level.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Key Performance Metrics**\n",
    "\n",
    "- **Accuracy**: 0.98  \n",
    "   Indicates that 98% of the predictions were correct, making the model highly accurate.\n",
    "\n",
    "- **Precision**: 0.99  \n",
    "   Precision of 0.99 suggests that 99% of positive predictions were true positives, highlighting the model’s reliability in identifying positive cases.\n",
    "\n",
    "- **Recall**: 0.99  \n",
    "   With a recall of 0.99, the model successfully identified 99% of the actual positive cases, suggesting excellent sensitivity.\n",
    "\n",
    "- **F1 Score**: 0.99  \n",
    "   The F1 Score of 0.99 represents a balance between precision and recall, further confirming the model’s effectiveness.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. ROC Curve and AUC Score**\n",
    "\n",
    "The ROC curve shows a near-perfect model with an **AUC of 1.00**, meaning the SVM has excellent discriminatory power to distinguish between classes. The model’s performance significantly exceeds the random classifier (represented by the diagonal line).\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "The SVM classifier achieved high accuracy, precision, recall, and F1 score, along with a perfect AUC score. This level of performance indicates that the SVM model is well-suited for this classification task, accurately identifying positive and negative cases with minimal misclassification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "y_pred_proba_knn = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"KNN - Accuracy: {accuracy_knn:.2f}, Precision: {precision_knn:.2f}, Recall: {recall_knn:.2f}, F1 Score: {f1_knn:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(cm_knn, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix - KNN\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_pred_proba_knn)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_pred_proba_knn)\n",
    "plt.plot(fpr_knn, tpr_knn, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc_knn:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.title(\"ROC Curve - KNN\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Model Summary\n",
    "\n",
    "#### Model Performance Metrics:\n",
    "- **Accuracy**: 0.91\n",
    "- **Precision**: 0.93\n",
    "- **Recall**: 0.97\n",
    "- **F1 Score**: 0.95\n",
    "\n",
    "These metrics indicate that the KNN model performs effectively in classifying the target labels, with a high balance between precision and recall. The F1 score of 0.95 suggests that the model manages both false positives and false negatives well, leading to reliable predictions.\n",
    "\n",
    "#### ROC Curve Analysis:\n",
    "The ROC curve for the KNN model (shown above) illustrates the trade-off between the True Positive Rate (TPR) and False Positive Rate (FPR). The Area Under the Curve (AUC) is 0.94, which indicates a strong ability of the model to distinguish between classes. A higher AUC value close to 1.0 implies a high level of discrimination, validating the effectiveness of the model in making correct predictions. \n",
    "\n",
    "#### Conclusion:\n",
    "With an accuracy of 0.91 and an AUC of 0.94, the KNN model is highly effective for this classification problem, demonstrating robustness in both sensitivity and specificity. This model is well-suited for applications where balanced performance across various metrics is essential.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train the model\n",
    "gradient_boosting_model = GradientBoostingClassifier(random_state=42)\n",
    "gradient_boosting_model.fit(X_train, y_train)\n",
    "y_pred_gradient_boosting = gradient_boosting_model.predict(X_test)\n",
    "y_pred_proba_gradient_boosting = gradient_boosting_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy_gradient_boosting = accuracy_score(y_test, y_pred_gradient_boosting)\n",
    "precision_gradient_boosting = precision_score(y_test, y_pred_gradient_boosting)\n",
    "recall_gradient_boosting = recall_score(y_test, y_pred_gradient_boosting)\n",
    "f1_gradient_boosting = f1_score(y_test, y_pred_gradient_boosting)\n",
    "\n",
    "print(f\"Gradient Boosting - Accuracy: {accuracy_gradient_boosting:.2f}, Precision: {precision_gradient_boosting:.2f}, Recall: {recall_gradient_boosting:.2f}, F1 Score: {f1_gradient_boosting:.2f}\")\n",
    "\n",
    "# Feature Importance\n",
    "importances = gradient_boosting_model.feature_importances_\n",
    "plt.barh(X.columns, importances, color=\"skyblue\")\n",
    "plt.title(\"Feature Importance - Gradient Boosting\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_gradient_boosting = confusion_matrix(y_test, y_pred_gradient_boosting)\n",
    "sns.heatmap(cm_gradient_boosting, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix - Gradient Boosting\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_gradient_boosting, tpr_gradient_boosting, _ = roc_curve(y_test, y_pred_proba_gradient_boosting)\n",
    "roc_auc_gradient_boosting = roc_auc_score(y_test, y_pred_proba_gradient_boosting)\n",
    "plt.plot(fpr_gradient_boosting, tpr_gradient_boosting, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc_gradient_boosting:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.title(\"ROC Curve - Gradient Boosting\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Model Summary\n",
    "\n",
    "#### 1. **Performance Metrics Overview:**\n",
    "\n",
    "   - **Accuracy**: The Gradient Boosting model achieved high accuracy, which signifies that it correctly classified the majority of instances in the dataset. High accuracy is especially desirable in tasks where the cost of misclassification is substantial.\n",
    "\n",
    "   - **Precision**: Precision was observed to be high, reflecting that when the model predicts a positive outcome, it is frequently correct. In real-world applications, a high precision score means that the model minimizes the number of false positives, which is crucial in contexts where incorrectly predicting a positive class (e.g., indicating an issue in vehicle maintenance) could lead to unnecessary interventions.\n",
    "\n",
    "   - **Recall**: The model exhibited high recall, indicating its effectiveness in identifying most of the true positive cases. High recall is particularly valuable in applications where missing a positive instance (such as failing to identify a maintenance issue) could result in significant consequences. The Gradient Boosting model is thus efficient in capturing almost all actual positives, keeping false negatives to a minimum.\n",
    "\n",
    "   - **F1 Score**: The F1 score combines precision and recall to provide a balanced metric, particularly useful in imbalanced datasets. A high F1 score means that the model performs well in both precision and recall, suggesting robustness in classification tasks.\n",
    "\n",
    "#### 2. **Feature Importance Analysis:**\n",
    "\n",
    "   Gradient Boosting models are powerful for feature importance analysis due to their iterative approach of fitting residuals, which inherently ranks features by their contribution to reducing error. In this model:\n",
    "\n",
    "   - **Vehicle Age** and **Reported Issues** were among the most impactful features, suggesting that these variables play a critical role in predicting the target outcome. For instance, older vehicles with a history of reported issues might be more prone to maintenance needs, which aligns with industry expectations.\n",
    "   \n",
    "   - **Brake Condition** and **Maintenance History** were also identified as key contributors. Their high importance indicates that the model recognizes the mechanical and maintenance state of the vehicle as strong indicators of the target variable. These insights align well with practical applications where the condition of critical components like brakes is vital for predicting vehicle reliability and necessary maintenance.\n",
    "\n",
    "#### 3. **Confusion Matrix Insights:**\n",
    "\n",
    "   The confusion matrix for the Gradient Boosting model demonstrates an almost perfect classification, with very few or no misclassifications across classes. This means:\n",
    "\n",
    "   - **True Negatives and True Positives**: High counts in both categories indicate the model’s proficiency in accurately distinguishing between positive and negative classes.\n",
    "   - **False Positives and False Negatives**: A near-zero count in these categories highlights the model’s low error rate, signifying that it is highly reliable in both identifying true positives and true negatives. This performance metric suggests that the model is particularly suitable for applications where both precision and recall are critical, such as early detection of maintenance needs.\n",
    "\n",
    "#### 4. **ROC Curve and AUC Score:**\n",
    "\n",
    "   The ROC-AUC score, close to 1.0, reveals the Gradient Boosting model's excellent ability to separate the positive and negative classes:\n",
    "\n",
    "   - **AUC (Area Under the Curve)**: An AUC near 1.0 signifies a high-performing model with a very low probability of misclassification. The ROC curve shows a strong true positive rate even at low false positive rates, suggesting that the model is well-calibrated and effective for real-world applications.\n",
    "   \n",
    "   - **Interpretation in Context**: In vehicle maintenance scenarios, a high AUC is critical as it ensures that the model can effectively distinguish between vehicles that need maintenance versus those that do not, reducing the risk of both over-maintenance and neglect.\n",
    "\n",
    "#### **Conclusion:**\n",
    "\n",
    "   The Gradient Boosting model exhibits a high level of precision, recall, and accuracy, making it a robust and reliable model for vehicle maintenance prediction. Its performance on key metrics and feature importance analysis suggests that it is well-suited for practical deployment in predictive maintenance systems. With the ability to accurately classify and prioritize vehicles that may require attention, this model provides a valuable tool for optimizing maintenance schedules, minimizing downtime, and improving overall vehicle reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and calculate accuracy as percentages\n",
    "accuracy_percentages = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100  # Scale to percentage\n",
    "    accuracy_percentages.append(accuracy)\n",
    "\n",
    "# Plot accuracy percentages\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = range(len(models))\n",
    "\n",
    "plt.bar(x, accuracy_percentages, color='skyblue', width=0.6)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy of Different Models (as Percentage)\")\n",
    "plt.xticks(x, models.keys(), rotation=45)\n",
    "plt.ylim(0, 100)  # Limit y-axis from 0 to 100%\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance comparison of various classification models indicates a generally high level of accuracy across the board, with each model achieving over 85%. Among them, Gradient Boosting, Random Forest, and Support Vector Machine (SVM) models demonstrate near-perfect accuracy, reaching close to 100%. This suggests that these ensemble and margin-based models might be particularly well-suited for the dataset, likely due to their ability to capture complex relationships within the data. Decision Trees, K-Nearest Neighbors (KNN), and Logistic Regression also perform robustly, though with slightly lower accuracy in comparison.\n",
    "\n",
    "The K-Nearest Neighbors model, which achieved an accuracy of 91% and had an AUC of 0.94 as per the ROC analysis, is competitive with other models. Its performance in terms of precision and recall was also high, making it a reliable model for applications that demand balanced predictions. However, its accuracy trails slightly behind that of Gradient Boosting and Random Forest, suggesting that while KNN is effective, it may not capture all intricate patterns as thoroughly as these other models. The high accuracy of Gradient Boosting and Random Forest likely stems from their ensemble nature, which combines multiple learners to improve generalization.\n",
    "\n",
    "In conclusion, while all models perform strongly, Gradient Boosting and Random Forest are standout performers, achieving near-100% accuracy, which may make them preferred choices for maximizing predictive accuracy in this particular setting. KNN, SVM, and Decision Trees are also highly effective and may be preferred if interpretability or simplicity is required. Logistic Regression, though slightly less accurate, could be beneficial for applications where a simpler, linear model suffices. The choice of model, therefore, can be guided by the specific requirements of the application, balancing the need for accuracy, interpretability, and computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Insights\n",
    "\n",
    "1. **Impact of Vehicle Age and Mileage**:  \n",
    "   - As vehicles age, they demand more frequent maintenance, with those over five years old requiring particular attention. There’s a clear correlation between vehicle age and maintenance needs, particularly with higher-mileage vehicles. This finding underscores the importance of targeted maintenance for older fleet vehicles to prevent major issues.\n",
    "\n",
    "2. **Fuel Efficiency Variations**:\n",
    "   - Smaller engine sizes tend to yield better fuel efficiency, with electric vehicles consistently outperforming traditional fuel types in this regard. This trend suggests that transitioning more vehicles to electric or lower engine sizes could improve fuel efficiency across the fleet.\n",
    "\n",
    "3. **Significance of Regular Service History**:  \n",
    "   - Vehicles with consistent service histories demonstrate fewer issues over time, regardless of age. Gaps in service history correlate with higher maintenance needs, indicating that regular maintenance plays a critical role in minimizing downtime and unexpected repairs.\n",
    "\n",
    "4. **Insurance Premium and Accident History**:\n",
    "   - Vehicles with higher accident histories generally incur greater insurance premiums, while those with fewer accidents and well-maintained components (like tires and brakes) see reduced costs. Effective vehicle maintenance may, therefore, contribute not only to lower repair costs but also to lower insurance premiums over time.\n",
    "\n",
    "5. **Most Common Issues - Battery and Brake Condition**:  \n",
    "   - Battery weakness and worn brake conditions are frequent across vehicles in the dataset, representing the two main areas where maintenance is often required. Given these findings, focusing on battery health and brake quality could significantly enhance vehicle reliability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Recommendations\n",
    "\n",
    "1. **Implement Predictive Maintenance**:  \n",
    "   - Develop a predictive maintenance model using metrics like age, mileage, and service history to forecast maintenance needs. This approach can help identify high-risk vehicles preemptively, optimizing repair schedules and reducing fleet downtime.\n",
    "\n",
    "2. **Encourage Transition to Electric Vehicles**:  \n",
    "   - Expanding the fleet with more electric vehicles could yield long-term cost savings, as these vehicles demonstrate higher fuel efficiency and generally require less maintenance. Replacing older, less efficient vehicles with electric options supports sustainability and cost-effectiveness.\n",
    "\n",
    "3. **Enhanced Focus on Key Components**:  \n",
    "   - Regular monitoring and maintenance of batteries and brakes are essential. Implementing real-time sensors for these components could alert fleet managers when wear levels are critical, preventing costly repairs and improving safety.\n",
    "\n",
    "4. **Optimize Insurance Premiums through Maintenance Standards**:  \n",
    "   - Leverage the improved maintenance record and low accident rate of well-maintained vehicles to negotiate more favorable insurance premiums. A proactive approach in maintenance could significantly lower insurance costs over time.\n",
    "\n",
    "5. **Regular Updates to Maintenance Procedures**:  \n",
    "   - Refine maintenance protocols based on insights from vehicles with robust service histories. Quarterly inspections for high-risk components can help ensure optimal fleet performance and reduce unexpected downtime.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The analysis of the vehicle maintenance dataset highlights several critical factors influencing the reliability and cost-effectiveness of the fleet, including vehicle age, mileage, fuel type, and service history. Older, high-mileage vehicles require more frequent repairs, particularly in areas like battery health and brake condition. The benefits of consistent maintenance are evident, as vehicles with well-documented service histories show fewer issues and greater longevity. Additionally, electric and smaller-engine vehicles have demonstrated higher fuel efficiency and lower maintenance demands, making them advantageous for both financial and sustainability goals.\n",
    "\n",
    "In summary, a proactive approach to fleet management through predictive maintenance, increased use of electric vehicles, and careful monitoring of key components can enhance operational efficiency while reducing costs. By optimizing insurance premiums and refining maintenance standards, fleet managers can support long-term sustainability and vehicle reliability. These strategies collectively create a resilient vehicle management system that minimizes downtime and maximizes safety, ultimately supporting both organizational objectives and financial health.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
